{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following is heavily inspired by Anas' work as it served as a basis and an introduction to pyTorch (coming from Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDFA(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, hidden_layers_number=1):\n",
    "        \n",
    "        super(SimpleDFA, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_layers_number = hidden_layers_number\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Use ModuleList for layers\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(input_size, hidden_size)] + \n",
    "            [nn.Linear(hidden_size, hidden_size) for _ in range(hidden_layers_number)] + \n",
    "            [nn.Linear(hidden_size, output_size)]\n",
    "        )\n",
    "        \n",
    "        self.activation = nn.Tanh()  # Use Tanh activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply activation to each hidden layer\n",
    "        for layer in self.layers[:-1]:  # All except the last layer\n",
    "            x = self.activation(layer(x))\n",
    "        # Final layer (output layer) without activation\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def Init_weights(self):\n",
    "        # Xavier init on weights\n",
    "        for layer in self.layers: \n",
    "            nn.init.xavier_uniform_(layer.weight) \n",
    "\n",
    "    \n",
    "    def Init_feedback(self):\n",
    "        # Create feedback matrices matching each layer's output size\n",
    "        self.B_hiddens = [torch.randn(self.hidden_size, self.output_size) * 0.01 for _ in range(self.hidden_layers_number)]\n",
    "        self.B_output = torch.randn(self.output_size, self.output_size) * 0.01  # Feedback for output layer\n",
    "\n",
    "        # Normalize feedback matrices\n",
    "        for i in range(len(self.B_hiddens)):\n",
    "            self.B_hiddens[i] /= self.B_hiddens[i].norm()\n",
    "        self.B_output /= self.B_output.norm()\n",
    "\n",
    "        return self.B_hiddens + [self.B_output]  # Feedback matrices for hidden layers + output\n",
    "\n",
    "\n",
    "    def forward_pass(self,Input,Target,loss_func):\n",
    "        \n",
    "        # Forward pass\n",
    "        Output = self.forward(Input)\n",
    "        loss = loss_func(Output, Target)\n",
    "        return Output, loss\n",
    "        \n",
    "    def activation_derivative(self, x):\n",
    "        \n",
    "        return 1 - self.activation(x)**2  # Derivative of Tanh activation function\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFA training step (UPDATING IN PROGRESS)\n",
    "\n",
    "check what's up with hidden_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfa_update_step(model, Bs, output, target, hidden_activations, inputs, learning_rate=0.01):\n",
    "    # Compute error at the output\n",
    "    error = output - target  # Compute error at the output layer\n",
    "\n",
    "    # Update the output layer first\n",
    "    feedback_signal_output = error * model.activation_derivative(output)\n",
    "    with torch.no_grad():\n",
    "        # Update output layer weights and biases\n",
    "        delta_w_out = torch.matmul(feedback_signal_output.T, hidden_activations[-1])\n",
    "        model.layers[-1].weight -= learning_rate * delta_w_out\n",
    "        delta_b_out = feedback_signal_output.sum(0)\n",
    "        model.layers[-1].bias -= learning_rate * delta_b_out\n",
    "\n",
    "    # Now, propagate backward through the hidden layers\n",
    "    for index in reversed(range(len(model.layers) - 1)):  # Hidden layers (in reverse order)\n",
    "        # Compute feedback signal for hidden layers\n",
    "        feedback_signal_hidden = torch.matmul(feedback_signal_output, Bs[index]) * model.activation_derivative(hidden_activations[index])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Update weights and biases for hidden layers\n",
    "            delta_w = torch.matmul(feedback_signal_hidden.T, hidden_activations[index - 1] if index > 0 else inputs)\n",
    "            model.layers[index].weight -= learning_rate * delta_w\n",
    "            delta_b = feedback_signal_hidden.sum(0)\n",
    "            model.layers[index].bias -= learning_rate * delta_b\n",
    "\n",
    "            # Prepare feedback signal for the next (previous) layer\n",
    "            feedback_signal_output = feedback_signal_hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, targets, loss_fn, learning_rate=0.01, epochs=1000):\n",
    "    # Initialize feedback matrices\n",
    "    Bs = model.Init_feedback()\n",
    "\n",
    "    losses = []  # To store the loss at each epoch\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "\n",
    "        # Pass data through each hidden layer and store activations\n",
    "        hidden_activations = []\n",
    "        x = data\n",
    "        foo  = 0\n",
    "        for layer in model.layers[:-1]:  # Collect activations for hidden layers only\n",
    "            print(foo); foo += 1\n",
    "            x = model.activation(layer(x))\n",
    "            hidden_activations.append(x)\n",
    "        print(\"Done with hidden activations\", hidden_activations)\n",
    "\n",
    "        output, loss = model.forward_pass(data, targets, loss_fn)\n",
    "\n",
    "        # Apply DFA update step\n",
    "        dfa_update_step(model, Bs, output, targets, hidden_activations, data, learning_rate)\n",
    "\n",
    "        # Store the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Print loss and accuracy every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "            # Compute accuracy\n",
    "            predictions = (output >= 0.5).float()  # Threshold the output to get binary predictions\n",
    "            correct = (predictions == targets).float().sum()\n",
    "            accuracy = correct / targets.size(0)\n",
    "            print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Plot the convergence of loss\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Convergence of Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.5479, -0.2376,  0.2062,  0.5403],\n",
      "        [ 0.5066,  0.2106,  0.4724, -0.0221],\n",
      "        [ 0.4073,  0.3051,  0.5439,  0.8004],\n",
      "        [ 0.3585,  0.6476,  0.7229,  0.4406]], grad_fn=<TanhBackward0>), tensor([[-0.2278,  0.2978,  0.1667,  0.3468],\n",
      "        [ 0.4382,  0.3575, -0.1588,  0.3722],\n",
      "        [ 0.2268,  0.0529,  0.3574,  0.3999],\n",
      "        [ 0.6244,  0.0911,  0.1653,  0.4043]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [0/1000], Loss: 0.28497806191444397\n",
      "Accuracy: 75.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.5307, -0.2663,  0.1833,  0.5302],\n",
      "        [ 0.4951,  0.1855,  0.4574, -0.0296],\n",
      "        [ 0.3680,  0.2511,  0.5107,  0.7914],\n",
      "        [ 0.3256,  0.6151,  0.7025,  0.4260]], grad_fn=<TanhBackward0>), tensor([[-0.1330,  0.3929,  0.2475,  0.4259],\n",
      "        [ 0.5049,  0.4327, -0.0879,  0.4410],\n",
      "        [ 0.3339,  0.1693,  0.4447,  0.4988],\n",
      "        [ 0.6961,  0.1985,  0.2540,  0.4954]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.5191, -0.2862,  0.1679,  0.5257],\n",
      "        [ 0.4924,  0.1726,  0.4508, -0.0253],\n",
      "        [ 0.3387,  0.2085,  0.4849,  0.7864],\n",
      "        [ 0.3067,  0.5918,  0.6888,  0.4240]], grad_fn=<TanhBackward0>), tensor([[-0.0812,  0.4434,  0.2852,  0.4642],\n",
      "        [ 0.5363,  0.4691, -0.0523,  0.4720],\n",
      "        [ 0.3850,  0.2299,  0.4821,  0.5460],\n",
      "        [ 0.7283,  0.2525,  0.2942,  0.5369]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.5118, -0.2999,  0.1580,  0.5250],\n",
      "        [ 0.4956,  0.1678,  0.4500, -0.0142],\n",
      "        [ 0.3180,  0.1759,  0.4655,  0.7846],\n",
      "        [ 0.2984,  0.5761,  0.6803,  0.4300]], grad_fn=<TanhBackward0>), tensor([[-0.0560,  0.4693,  0.2995,  0.4815],\n",
      "        [ 0.5498,  0.4849, -0.0370,  0.4837],\n",
      "        [ 0.4071,  0.2592,  0.4946,  0.5677],\n",
      "        [ 0.7422,  0.2773,  0.3096,  0.5541]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 5.0679e-01, -3.1027e-01,  1.5097e-01,  5.2603e-01],\n",
      "        [ 5.0164e-01,  1.6735e-01,  4.5216e-01,  9.0659e-05],\n",
      "        [ 3.0196e-01,  1.4884e-01,  4.4954e-01,  7.8428e-01],\n",
      "        [ 2.9566e-01,  5.6472e-01,  6.7475e-01,  4.3969e-01]],\n",
      "       grad_fn=<TanhBackward0>), tensor([[-0.0441,  0.4834,  0.3024,  0.4890],\n",
      "        [ 0.5551,  0.4909, -0.0318,  0.4864],\n",
      "        [ 0.4157,  0.2737,  0.4958,  0.5780],\n",
      "        [ 0.7482,  0.2884,  0.3133,  0.5603]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.5029, -0.3190,  0.1453,  0.5279],\n",
      "        [ 0.5089,  0.1689,  0.4556,  0.0155],\n",
      "        [ 0.2882,  0.1246,  0.4352,  0.7847],\n",
      "        [ 0.2955,  0.5555,  0.6705,  0.4508]], grad_fn=<TanhBackward0>), tensor([[-0.0387,  0.4921,  0.3000,  0.4917],\n",
      "        [ 0.5567,  0.4924, -0.0318,  0.4846],\n",
      "        [ 0.4179,  0.2813,  0.4918,  0.5828],\n",
      "        [ 0.7506,  0.2930,  0.3113,  0.5612]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4995, -0.3270,  0.1402,  0.5300],\n",
      "        [ 0.5165,  0.1713,  0.4594,  0.0312],\n",
      "        [ 0.2754,  0.1017,  0.4215,  0.7854],\n",
      "        [ 0.2965,  0.5473,  0.6668,  0.4623]], grad_fn=<TanhBackward0>), tensor([[-0.0364,  0.4982,  0.2950,  0.4920],\n",
      "        [ 0.5566,  0.4917, -0.0345,  0.4805],\n",
      "        [ 0.4169,  0.2855,  0.4853,  0.5849],\n",
      "        [ 0.7513,  0.2942,  0.3061,  0.5592]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4962, -0.3346,  0.1352,  0.5322],\n",
      "        [ 0.5242,  0.1741,  0.4634,  0.0467],\n",
      "        [ 0.2629,  0.0795,  0.4079,  0.7861],\n",
      "        [ 0.2978,  0.5396,  0.6633,  0.4736]], grad_fn=<TanhBackward0>), tensor([[-0.0357,  0.5031,  0.2887,  0.4910],\n",
      "        [ 0.5557,  0.4897, -0.0391,  0.4750],\n",
      "        [ 0.4142,  0.2882,  0.4777,  0.5855],\n",
      "        [ 0.7511,  0.2936,  0.2990,  0.5556]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4930, -0.3420,  0.1302,  0.5343],\n",
      "        [ 0.5318,  0.1771,  0.4674,  0.0619],\n",
      "        [ 0.2504,  0.0577,  0.3941,  0.7869],\n",
      "        [ 0.2991,  0.5321,  0.6598,  0.4846]], grad_fn=<TanhBackward0>), tensor([[-0.0357,  0.5074,  0.2818,  0.4892],\n",
      "        [ 0.5544,  0.4869, -0.0449,  0.4684],\n",
      "        [ 0.4106,  0.2900,  0.4695,  0.5851],\n",
      "        [ 0.7505,  0.2917,  0.2905,  0.5509]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4897, -0.3493,  0.1251,  0.5364],\n",
      "        [ 0.5393,  0.1802,  0.4712,  0.0768],\n",
      "        [ 0.2379,  0.0361,  0.3800,  0.7875],\n",
      "        [ 0.3004,  0.5248,  0.6561,  0.4951]], grad_fn=<TanhBackward0>), tensor([[-0.0360,  0.5113,  0.2744,  0.4868],\n",
      "        [ 0.5530,  0.4835, -0.0519,  0.4610],\n",
      "        [ 0.4064,  0.2915,  0.4610,  0.5841],\n",
      "        [ 0.7496,  0.2889,  0.2809,  0.5451]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4864, -0.3565,  0.1198,  0.5383],\n",
      "        [ 0.5465,  0.1834,  0.4749,  0.0912],\n",
      "        [ 0.2251,  0.0148,  0.3656,  0.7881],\n",
      "        [ 0.3015,  0.5177,  0.6523,  0.5051]], grad_fn=<TanhBackward0>), tensor([[-0.0366,  0.5151,  0.2667,  0.4839],\n",
      "        [ 0.5514,  0.4796, -0.0599,  0.4526],\n",
      "        [ 0.4019,  0.2930,  0.4525,  0.5826],\n",
      "        [ 0.7484,  0.2852,  0.2702,  0.5384]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4829, -0.3636,  0.1144,  0.5400],\n",
      "        [ 0.5536,  0.1867,  0.4785,  0.1052],\n",
      "        [ 0.2123, -0.0063,  0.3509,  0.7886],\n",
      "        [ 0.3025,  0.5107,  0.6484,  0.5148]], grad_fn=<TanhBackward0>), tensor([[-0.0372,  0.5187,  0.2588,  0.4805],\n",
      "        [ 0.5496,  0.4750, -0.0691,  0.4434],\n",
      "        [ 0.3972,  0.2945,  0.4440,  0.5805],\n",
      "        [ 0.7470,  0.2808,  0.2585,  0.5308]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4794, -0.3706,  0.1089,  0.5417],\n",
      "        [ 0.5604,  0.1900,  0.4819,  0.1188],\n",
      "        [ 0.1993, -0.0270,  0.3358,  0.7891],\n",
      "        [ 0.3033,  0.5039,  0.6443,  0.5240]], grad_fn=<TanhBackward0>), tensor([[-0.0378,  0.5223,  0.2506,  0.4767],\n",
      "        [ 0.5477,  0.4697, -0.0795,  0.4331],\n",
      "        [ 0.3924,  0.2962,  0.4354,  0.5781],\n",
      "        [ 0.7455,  0.2757,  0.2456,  0.5222]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4759, -0.3774,  0.1032,  0.5433],\n",
      "        [ 0.5672,  0.1936,  0.4853,  0.1321],\n",
      "        [ 0.1861, -0.0472,  0.3204,  0.7895],\n",
      "        [ 0.3041,  0.4974,  0.6401,  0.5329]], grad_fn=<TanhBackward0>), tensor([[-0.0385,  0.5257,  0.2421,  0.4723],\n",
      "        [ 0.5456,  0.4637, -0.0912,  0.4216],\n",
      "        [ 0.3876,  0.2981,  0.4269,  0.5751],\n",
      "        [ 0.7437,  0.2696,  0.2316,  0.5126]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4723, -0.3840,  0.0974,  0.5448],\n",
      "        [ 0.5738,  0.1973,  0.4885,  0.1451],\n",
      "        [ 0.1730, -0.0669,  0.3047,  0.7898],\n",
      "        [ 0.3049,  0.4912,  0.6358,  0.5414]], grad_fn=<TanhBackward0>), tensor([[-0.0392,  0.5289,  0.2333,  0.4675],\n",
      "        [ 0.5432,  0.4568, -0.1043,  0.4090],\n",
      "        [ 0.3829,  0.3003,  0.4185,  0.5716],\n",
      "        [ 0.7417,  0.2627,  0.2163,  0.5017]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4687, -0.3904,  0.0915,  0.5462],\n",
      "        [ 0.5803,  0.2012,  0.4917,  0.1577],\n",
      "        [ 0.1599, -0.0860,  0.2889,  0.7901],\n",
      "        [ 0.3057,  0.4854,  0.6315,  0.5496]], grad_fn=<TanhBackward0>), tensor([[-0.0400,  0.5319,  0.2240,  0.4620],\n",
      "        [ 0.5405,  0.4489, -0.1189,  0.3949],\n",
      "        [ 0.3783,  0.3028,  0.4100,  0.5677],\n",
      "        [ 0.7395,  0.2548,  0.1996,  0.4895]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4652, -0.3966,  0.0856,  0.5476],\n",
      "        [ 0.5868,  0.2053,  0.4949,  0.1701],\n",
      "        [ 0.1468, -0.1045,  0.2729,  0.7904],\n",
      "        [ 0.3065,  0.4801,  0.6271,  0.5576]], grad_fn=<TanhBackward0>), tensor([[-0.0409,  0.5347,  0.2143,  0.4559],\n",
      "        [ 0.5374,  0.4399, -0.1351,  0.3792],\n",
      "        [ 0.3739,  0.3055,  0.4016,  0.5632],\n",
      "        [ 0.7370,  0.2459,  0.1814,  0.4758]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4616, -0.4025,  0.0797,  0.5489],\n",
      "        [ 0.5931,  0.2098,  0.4980,  0.1822],\n",
      "        [ 0.1339, -0.1222,  0.2568,  0.7907],\n",
      "        [ 0.3076,  0.4752,  0.6227,  0.5654]], grad_fn=<TanhBackward0>), tensor([[-0.0418,  0.5372,  0.2040,  0.4491],\n",
      "        [ 0.5338,  0.4295, -0.1530,  0.3618],\n",
      "        [ 0.3696,  0.3084,  0.3931,  0.5581],\n",
      "        [ 0.7342,  0.2359,  0.1615,  0.4605]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4582, -0.4081,  0.0738,  0.5502],\n",
      "        [ 0.5995,  0.2145,  0.5012,  0.1940],\n",
      "        [ 0.1213, -0.1391,  0.2406,  0.7910],\n",
      "        [ 0.3088,  0.4709,  0.6184,  0.5730]], grad_fn=<TanhBackward0>), tensor([[-0.0430,  0.5394,  0.1932,  0.4415],\n",
      "        [ 0.5297,  0.4178, -0.1728,  0.3425],\n",
      "        [ 0.3656,  0.3116,  0.3846,  0.5524],\n",
      "        [ 0.7310,  0.2245,  0.1400,  0.4433]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4548, -0.4135,  0.0679,  0.5514],\n",
      "        [ 0.6058,  0.2195,  0.5044,  0.2057],\n",
      "        [ 0.1089, -0.1552,  0.2246,  0.7913],\n",
      "        [ 0.3103,  0.4672,  0.6142,  0.5803]], grad_fn=<TanhBackward0>), tensor([[-0.0444,  0.5412,  0.1816,  0.4331],\n",
      "        [ 0.5249,  0.4044, -0.1943,  0.3211],\n",
      "        [ 0.3619,  0.3149,  0.3760,  0.5461],\n",
      "        [ 0.7275,  0.2118,  0.1166,  0.4242]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4516, -0.4185,  0.0621,  0.5527],\n",
      "        [ 0.6121,  0.2248,  0.5076,  0.2170],\n",
      "        [ 0.0968, -0.1704,  0.2087,  0.7916],\n",
      "        [ 0.3120,  0.4641,  0.6102,  0.5876]], grad_fn=<TanhBackward0>), tensor([[-0.0460,  0.5425,  0.1693,  0.4238],\n",
      "        [ 0.5194,  0.3893, -0.2178,  0.2973],\n",
      "        [ 0.3584,  0.3183,  0.3673,  0.5391],\n",
      "        [ 0.7235,  0.1976,  0.0913,  0.4029]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4484, -0.4232,  0.0564,  0.5539],\n",
      "        [ 0.6184,  0.2304,  0.5110,  0.2282],\n",
      "        [ 0.0852, -0.1847,  0.1930,  0.7919],\n",
      "        [ 0.3142,  0.4616,  0.6063,  0.5947]], grad_fn=<TanhBackward0>), tensor([[-0.0480,  0.5433,  0.1563,  0.4135],\n",
      "        [ 0.5130,  0.3723, -0.2431,  0.2710],\n",
      "        [ 0.3551,  0.3218,  0.3585,  0.5314],\n",
      "        [ 0.7190,  0.1818,  0.0641,  0.3791]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4455, -0.4276,  0.0508,  0.5551],\n",
      "        [ 0.6248,  0.2362,  0.5144,  0.2391],\n",
      "        [ 0.0741, -0.1981,  0.1776,  0.7923],\n",
      "        [ 0.3167,  0.4597,  0.6026,  0.6016]], grad_fn=<TanhBackward0>), tensor([[-0.0504,  0.5436,  0.1425,  0.4022],\n",
      "        [ 0.5058,  0.3532, -0.2702,  0.2421],\n",
      "        [ 0.3520,  0.3253,  0.3497,  0.5229],\n",
      "        [ 0.7139,  0.1643,  0.0350,  0.3527]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4427, -0.4317,  0.0454,  0.5563],\n",
      "        [ 0.6311,  0.2423,  0.5178,  0.2498],\n",
      "        [ 0.0634, -0.2107,  0.1625,  0.7927],\n",
      "        [ 0.3195,  0.4584,  0.5992,  0.6084]], grad_fn=<TanhBackward0>), tensor([[-0.0531,  0.5433,  0.1280,  0.3897],\n",
      "        [ 0.4976,  0.3320, -0.2989,  0.2103],\n",
      "        [ 0.3491,  0.3286,  0.3407,  0.5136],\n",
      "        [ 0.7083,  0.1451,  0.0040,  0.3236]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4400, -0.4356,  0.0402,  0.5575],\n",
      "        [ 0.6373,  0.2485,  0.5213,  0.2602],\n",
      "        [ 0.0533, -0.2224,  0.1479,  0.7932],\n",
      "        [ 0.3228,  0.4577,  0.5960,  0.6151]], grad_fn=<TanhBackward0>), tensor([[-0.0563,  0.5424,  0.1128,  0.3760],\n",
      "        [ 0.4884,  0.3085, -0.3290,  0.1756],\n",
      "        [ 0.3463,  0.3319,  0.3318,  0.5035],\n",
      "        [ 0.7020,  0.1240, -0.0288,  0.2915]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4376, -0.4392,  0.0352,  0.5586],\n",
      "        [ 0.6436,  0.2548,  0.5249,  0.2702],\n",
      "        [ 0.0438, -0.2332,  0.1337,  0.7936],\n",
      "        [ 0.3264,  0.4575,  0.5931,  0.6215]], grad_fn=<TanhBackward0>), tensor([[-0.0600,  0.5410,  0.0970,  0.3612],\n",
      "        [ 0.4781,  0.2828, -0.3601,  0.1381],\n",
      "        [ 0.3438,  0.3350,  0.3229,  0.4926],\n",
      "        [ 0.6951,  0.1012, -0.0631,  0.2564]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4353, -0.4425,  0.0303,  0.5597],\n",
      "        [ 0.6497,  0.2612,  0.5285,  0.2799],\n",
      "        [ 0.0349, -0.2432,  0.1200,  0.7942],\n",
      "        [ 0.3304,  0.4578,  0.5905,  0.6278]], grad_fn=<TanhBackward0>), tensor([[-0.0641,  0.5390,  0.0807,  0.3452],\n",
      "        [ 0.4666,  0.2550, -0.3921,  0.0978],\n",
      "        [ 0.3413,  0.3380,  0.3141,  0.4809],\n",
      "        [ 0.6874,  0.0768, -0.0986,  0.2184]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4332, -0.4457,  0.0256,  0.5607],\n",
      "        [ 0.6558,  0.2675,  0.5320,  0.2891],\n",
      "        [ 0.0266, -0.2525,  0.1069,  0.7947],\n",
      "        [ 0.3347,  0.4584,  0.5881,  0.6338]], grad_fn=<TanhBackward0>), tensor([[-0.0687,  0.5365,  0.0641,  0.3282],\n",
      "        [ 0.4541,  0.2252, -0.4243,  0.0551],\n",
      "        [ 0.3390,  0.3409,  0.3056,  0.4686],\n",
      "        [ 0.6791,  0.0509, -0.1349,  0.1777]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4312, -0.4487,  0.0210,  0.5616],\n",
      "        [ 0.6617,  0.2735,  0.5355,  0.2976],\n",
      "        [ 0.0189, -0.2611,  0.0943,  0.7953],\n",
      "        [ 0.3393,  0.4593,  0.5859,  0.6395]], grad_fn=<TanhBackward0>), tensor([[-0.0736,  0.5338,  0.0475,  0.3104],\n",
      "        [ 0.4405,  0.1939, -0.4564,  0.0104],\n",
      "        [ 0.3369,  0.3438,  0.2976,  0.4557],\n",
      "        [ 0.6701,  0.0240, -0.1715,  0.1347]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4293, -0.4516,  0.0166,  0.5624],\n",
      "        [ 0.6674,  0.2792,  0.5387,  0.3055],\n",
      "        [ 0.0117, -0.2690,  0.0823,  0.7959],\n",
      "        [ 0.3440,  0.4604,  0.5839,  0.6449]], grad_fn=<TanhBackward0>), tensor([[-0.0788,  0.5309,  0.0310,  0.2919],\n",
      "        [ 0.4260,  0.1616, -0.4878, -0.0355],\n",
      "        [ 0.3349,  0.3468,  0.2902,  0.4426],\n",
      "        [ 0.6605, -0.0035, -0.2079,  0.0900]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4275, -0.4545,  0.0122,  0.5629],\n",
      "        [ 0.6728,  0.2844,  0.5417,  0.3125],\n",
      "        [ 0.0052, -0.2764,  0.0708,  0.7964],\n",
      "        [ 0.3489,  0.4614,  0.5819,  0.6497]], grad_fn=<TanhBackward0>), tensor([[-0.0841,  0.5282,  0.0149,  0.2732],\n",
      "        [ 0.4108,  0.1289, -0.5183, -0.0817],\n",
      "        [ 0.3331,  0.3502,  0.2834,  0.4294],\n",
      "        [ 0.6504, -0.0309, -0.2436,  0.0444]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4258, -0.4575,  0.0078,  0.5632],\n",
      "        [ 0.6779,  0.2889,  0.5443,  0.3185],\n",
      "        [-0.0008, -0.2834,  0.0599,  0.7969],\n",
      "        [ 0.3537,  0.4623,  0.5800,  0.6541]], grad_fn=<TanhBackward0>), tensor([[-8.9404e-02,  5.2579e-01, -4.9907e-04,  2.5455e-01],\n",
      "        [ 3.9510e-01,  9.6653e-02, -5.4722e-01, -1.2727e-01],\n",
      "        [ 3.3162e-01,  3.5402e-01,  2.7753e-01,  4.1637e-01],\n",
      "        [ 6.4006e-01, -5.7775e-02, -2.7808e-01, -1.0778e-03]],\n",
      "       grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4240, -0.4607,  0.0034,  0.5632],\n",
      "        [ 0.6827,  0.2924,  0.5465,  0.3233],\n",
      "        [-0.0063, -0.2899,  0.0495,  0.7973],\n",
      "        [ 0.3585,  0.4628,  0.5780,  0.6578]], grad_fn=<TanhBackward0>), tensor([[-0.0945,  0.5240, -0.0151,  0.2365],\n",
      "        [ 0.3793,  0.0657, -0.5745, -0.1712],\n",
      "        [ 0.3305,  0.3585,  0.2725,  0.4039],\n",
      "        [ 0.6296, -0.0832, -0.3109, -0.0455]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4223, -0.4640, -0.0012,  0.5627],\n",
      "        [ 0.6870,  0.2949,  0.5481,  0.3268],\n",
      "        [-0.0112, -0.2960,  0.0396,  0.7976],\n",
      "        [ 0.3632,  0.4630,  0.5759,  0.6608]], grad_fn=<TanhBackward0>), tensor([[-0.0994,  0.5231, -0.0289,  0.2193],\n",
      "        [ 0.3636,  0.0369, -0.5997, -0.2125],\n",
      "        [ 0.3296,  0.3636,  0.2683,  0.3922],\n",
      "        [ 0.6193, -0.1067, -0.3418, -0.0880]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4204, -0.4676, -0.0059,  0.5619],\n",
      "        [ 0.6908,  0.2962,  0.5490,  0.3288],\n",
      "        [-0.0155, -0.3018,  0.0302,  0.7978],\n",
      "        [ 0.3678,  0.4627,  0.5737,  0.6631]], grad_fn=<TanhBackward0>), tensor([[-0.1038,  0.5231, -0.0417,  0.2033],\n",
      "        [ 0.3486,  0.0110, -0.6230, -0.2506],\n",
      "        [ 0.3292,  0.3695,  0.2648,  0.3813],\n",
      "        [ 0.6093, -0.1276, -0.3705, -0.1277]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4185, -0.4715, -0.0107,  0.5605],\n",
      "        [ 0.6942,  0.2961,  0.5492,  0.3293],\n",
      "        [-0.0192, -0.3074,  0.0214,  0.7978],\n",
      "        [ 0.3721,  0.4617,  0.5712,  0.6646]], grad_fn=<TanhBackward0>), tensor([[-0.1077,  0.5243, -0.0537,  0.1887],\n",
      "        [ 0.3344, -0.0115, -0.6442, -0.2849],\n",
      "        [ 0.3290,  0.3761,  0.2618,  0.3713],\n",
      "        [ 0.6000, -0.1457, -0.3970, -0.1643]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4166, -0.4757, -0.0158,  0.5587],\n",
      "        [ 0.6971,  0.2946,  0.5487,  0.3281],\n",
      "        [-0.0224, -0.3126,  0.0132,  0.7978],\n",
      "        [ 0.3763,  0.4602,  0.5686,  0.6653]], grad_fn=<TanhBackward0>), tensor([[-0.1112,  0.5266, -0.0650,  0.1754],\n",
      "        [ 0.3214, -0.0301, -0.6636, -0.3152],\n",
      "        [ 0.3290,  0.3833,  0.2591,  0.3621],\n",
      "        [ 0.5915, -0.1606, -0.4214, -0.1973]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4145, -0.4802, -0.0210,  0.5563],\n",
      "        [ 0.6996,  0.2917,  0.5474,  0.3252],\n",
      "        [-0.0249, -0.3175,  0.0055,  0.7977],\n",
      "        [ 0.3804,  0.4580,  0.5657,  0.6653]], grad_fn=<TanhBackward0>), tensor([[-0.1143,  0.5300, -0.0757,  0.1633],\n",
      "        [ 0.3096, -0.0449, -0.6811, -0.3418],\n",
      "        [ 0.3291,  0.3907,  0.2562,  0.3535],\n",
      "        [ 0.5838, -0.1726, -0.4439, -0.2271]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4124, -0.4850, -0.0265,  0.5535],\n",
      "        [ 0.7016,  0.2874,  0.5454,  0.3208],\n",
      "        [-0.0266, -0.3221, -0.0015,  0.7974],\n",
      "        [ 0.3844,  0.4553,  0.5627,  0.6644]], grad_fn=<TanhBackward0>), tensor([[-0.1171,  0.5342, -0.0863,  0.1523],\n",
      "        [ 0.2991, -0.0559, -0.6971, -0.3647],\n",
      "        [ 0.3290,  0.3982,  0.2530,  0.3452],\n",
      "        [ 0.5770, -0.1817, -0.4647, -0.2537]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4103, -0.4901, -0.0320,  0.5501],\n",
      "        [ 0.7032,  0.2819,  0.5427,  0.3149],\n",
      "        [-0.0277, -0.3263, -0.0078,  0.7971],\n",
      "        [ 0.3884,  0.4520,  0.5596,  0.6629]], grad_fn=<TanhBackward0>), tensor([[-0.1198,  0.5391, -0.0967,  0.1421],\n",
      "        [ 0.2898, -0.0632, -0.7117, -0.3844],\n",
      "        [ 0.3287,  0.4055,  0.2491,  0.3369],\n",
      "        [ 0.5709, -0.1883, -0.4840, -0.2776]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4082, -0.4955, -0.0378,  0.5464],\n",
      "        [ 0.7046,  0.2751,  0.5394,  0.3075],\n",
      "        [-0.0281, -0.3302, -0.0135,  0.7968],\n",
      "        [ 0.3925,  0.4484,  0.5564,  0.6608]], grad_fn=<TanhBackward0>), tensor([[-0.1225,  0.5446, -0.1071,  0.1325],\n",
      "        [ 0.2816, -0.0674, -0.7251, -0.4012],\n",
      "        [ 0.3279,  0.4125,  0.2443,  0.3283],\n",
      "        [ 0.5656, -0.1927, -0.5022, -0.2991]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4061, -0.5010, -0.0436,  0.5422],\n",
      "        [ 0.7056,  0.2673,  0.5356,  0.2988],\n",
      "        [-0.0277, -0.3337, -0.0185,  0.7964],\n",
      "        [ 0.3967,  0.4444,  0.5532,  0.6582]], grad_fn=<TanhBackward0>), tensor([[-0.1253,  0.5506, -0.1178,  0.1234],\n",
      "        [ 0.2744, -0.0686, -0.7374, -0.4155],\n",
      "        [ 0.3267,  0.4190,  0.2386,  0.3194],\n",
      "        [ 0.5609, -0.1953, -0.5194, -0.3187]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4039, -0.5068, -0.0496,  0.5376],\n",
      "        [ 0.7064,  0.2584,  0.5312,  0.2888],\n",
      "        [-0.0267, -0.3367, -0.0229,  0.7960],\n",
      "        [ 0.4011,  0.4401,  0.5501,  0.6550]], grad_fn=<TanhBackward0>), tensor([[-0.1283,  0.5568, -0.1285,  0.1147],\n",
      "        [ 0.2679, -0.0672, -0.7488, -0.4276],\n",
      "        [ 0.3249,  0.4249,  0.2319,  0.3101],\n",
      "        [ 0.5566, -0.1964, -0.5357, -0.3366]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.4018, -0.5126, -0.0556,  0.5326],\n",
      "        [ 0.7070,  0.2487,  0.5263,  0.2778],\n",
      "        [-0.0250, -0.3394, -0.0267,  0.7955],\n",
      "        [ 0.4056,  0.4357,  0.5469,  0.6514]], grad_fn=<TanhBackward0>), tensor([[-0.1315,  0.5633, -0.1394,  0.1061],\n",
      "        [ 0.2621, -0.0635, -0.7594, -0.4379],\n",
      "        [ 0.3226,  0.4302,  0.2243,  0.3001],\n",
      "        [ 0.5528, -0.1962, -0.5512, -0.3531]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3998, -0.5186, -0.0617,  0.5274],\n",
      "        [ 0.7075,  0.2381,  0.5210,  0.2657],\n",
      "        [-0.0227, -0.3417, -0.0299,  0.7951],\n",
      "        [ 0.4104,  0.4311,  0.5439,  0.6475]], grad_fn=<TanhBackward0>), tensor([[-0.1349,  0.5701, -0.1503,  0.0979],\n",
      "        [ 0.2568, -0.0578, -0.7693, -0.4465],\n",
      "        [ 0.3198,  0.4349,  0.2158,  0.2897],\n",
      "        [ 0.5492, -0.1951, -0.5660, -0.3684]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3977, -0.5248, -0.0680,  0.5218],\n",
      "        [ 0.7078,  0.2269,  0.5154,  0.2528],\n",
      "        [-0.0198, -0.3437, -0.0326,  0.7947],\n",
      "        [ 0.4153,  0.4264,  0.5409,  0.6433]], grad_fn=<TanhBackward0>), tensor([[-0.1384,  0.5770, -0.1613,  0.0899],\n",
      "        [ 0.2520, -0.0502, -0.7784, -0.4536],\n",
      "        [ 0.3166,  0.4391,  0.2065,  0.2787],\n",
      "        [ 0.5459, -0.1931, -0.5802, -0.3826]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3957, -0.5309, -0.0743,  0.5159],\n",
      "        [ 0.7080,  0.2150,  0.5094,  0.2390],\n",
      "        [-0.0165, -0.3453, -0.0348,  0.7944],\n",
      "        [ 0.4205,  0.4217,  0.5381,  0.6388]], grad_fn=<TanhBackward0>), tensor([[-0.1421,  0.5840, -0.1721,  0.0821],\n",
      "        [ 0.2475, -0.0410, -0.7869, -0.4594],\n",
      "        [ 0.3129,  0.4428,  0.1966,  0.2673],\n",
      "        [ 0.5427, -0.1905, -0.5937, -0.3960]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3936, -0.5372, -0.0807,  0.5098],\n",
      "        [ 0.7082,  0.2026,  0.5030,  0.2245],\n",
      "        [-0.0126, -0.3466, -0.0366,  0.7940],\n",
      "        [ 0.4258,  0.4170,  0.5353,  0.6341]], grad_fn=<TanhBackward0>), tensor([[-0.1459,  0.5913, -0.1828,  0.0747],\n",
      "        [ 0.2432, -0.0304, -0.7949, -0.4640],\n",
      "        [ 0.3090,  0.4461,  0.1862,  0.2556],\n",
      "        [ 0.5398, -0.1874, -0.6066, -0.4085]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3916, -0.5435, -0.0871,  0.5034],\n",
      "        [ 0.7082,  0.1898,  0.4964,  0.2093],\n",
      "        [-0.0084, -0.3475, -0.0379,  0.7937],\n",
      "        [ 0.4313,  0.4124,  0.5327,  0.6292]], grad_fn=<TanhBackward0>), tensor([[-0.1498,  0.5987, -0.1932,  0.0676],\n",
      "        [ 0.2392, -0.0184, -0.8022, -0.4675],\n",
      "        [ 0.3047,  0.4490,  0.1753,  0.2435],\n",
      "        [ 0.5369, -0.1839, -0.6190, -0.4202]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3896, -0.5498, -0.0937,  0.4968],\n",
      "        [ 0.7082,  0.1765,  0.4895,  0.1936],\n",
      "        [-0.0038, -0.3482, -0.0389,  0.7935],\n",
      "        [ 0.4370,  0.4079,  0.5302,  0.6242]], grad_fn=<TanhBackward0>), tensor([[-0.1537,  0.6063, -0.2033,  0.0609],\n",
      "        [ 0.2354, -0.0052, -0.8091, -0.4700],\n",
      "        [ 0.3003,  0.4515,  0.1642,  0.2311],\n",
      "        [ 0.5342, -0.1802, -0.6308, -0.4312]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3876, -0.5561, -0.1003,  0.4900],\n",
      "        [ 0.7082,  0.1630,  0.4824,  0.1774],\n",
      "        [ 0.0012, -0.3485, -0.0395,  0.7933],\n",
      "        [ 0.4428,  0.4035,  0.5278,  0.6191]], grad_fn=<TanhBackward0>), tensor([[-0.1575,  0.6140, -0.2131,  0.0545],\n",
      "        [ 0.2318,  0.0091, -0.8155, -0.4715],\n",
      "        [ 0.2957,  0.4537,  0.1527,  0.2186],\n",
      "        [ 0.5316, -0.1763, -0.6420, -0.4417]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3856, -0.5623, -0.1070,  0.4831],\n",
      "        [ 0.7081,  0.1493,  0.4750,  0.1610],\n",
      "        [ 0.0064, -0.3486, -0.0399,  0.7933],\n",
      "        [ 0.4488,  0.3993,  0.5256,  0.6141]], grad_fn=<TanhBackward0>), tensor([[-0.1613,  0.6218, -0.2224,  0.0486],\n",
      "        [ 0.2284,  0.0244, -0.8214, -0.4722],\n",
      "        [ 0.2910,  0.4557,  0.1412,  0.2059],\n",
      "        [ 0.5291, -0.1723, -0.6527, -0.4515]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3836, -0.5686, -0.1137,  0.4761],\n",
      "        [ 0.7080,  0.1354,  0.4675,  0.1442],\n",
      "        [ 0.0119, -0.3483, -0.0399,  0.7932],\n",
      "        [ 0.4549,  0.3954,  0.5234,  0.6091]], grad_fn=<TanhBackward0>), tensor([[-0.1650,  0.6297, -0.2314,  0.0430],\n",
      "        [ 0.2252,  0.0405, -0.8270, -0.4722],\n",
      "        [ 0.2863,  0.4573,  0.1295,  0.1932],\n",
      "        [ 0.5267, -0.1684, -0.6628, -0.4608]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3816, -0.5747, -0.1205,  0.4690],\n",
      "        [ 0.7079,  0.1216,  0.4598,  0.1274],\n",
      "        [ 0.0176, -0.3478, -0.0397,  0.7933],\n",
      "        [ 0.4611,  0.3917,  0.5215,  0.6041]], grad_fn=<TanhBackward0>), tensor([[-0.1687,  0.6378, -0.2400,  0.0379],\n",
      "        [ 0.2222,  0.0573, -0.8321, -0.4714],\n",
      "        [ 0.2816,  0.4588,  0.1178,  0.1804],\n",
      "        [ 0.5244, -0.1646, -0.6725, -0.4696]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3796, -0.5808, -0.1273,  0.4618],\n",
      "        [ 0.7078,  0.1077,  0.4520,  0.1105],\n",
      "        [ 0.0235, -0.3469, -0.0393,  0.7935],\n",
      "        [ 0.4674,  0.3883,  0.5197,  0.5993]], grad_fn=<TanhBackward0>), tensor([[-0.1722,  0.6459, -0.2482,  0.0332],\n",
      "        [ 0.2193,  0.0747, -0.8369, -0.4700],\n",
      "        [ 0.2769,  0.4599,  0.1061,  0.1676],\n",
      "        [ 0.5223, -0.1610, -0.6816, -0.4780]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3775, -0.5867, -0.1341,  0.4545],\n",
      "        [ 0.7078,  0.0940,  0.4442,  0.0937],\n",
      "        [ 0.0295, -0.3458, -0.0387,  0.7937],\n",
      "        [ 0.4738,  0.3853,  0.5180,  0.5947]], grad_fn=<TanhBackward0>), tensor([[-0.1755,  0.6540, -0.2559,  0.0289],\n",
      "        [ 0.2168,  0.0926, -0.8414, -0.4680],\n",
      "        [ 0.2722,  0.4609,  0.0945,  0.1549],\n",
      "        [ 0.5203, -0.1578, -0.6903, -0.4859]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3755, -0.5926, -0.1410,  0.4473],\n",
      "        [ 0.7077,  0.0805,  0.4363,  0.0771],\n",
      "        [ 0.0356, -0.3444, -0.0379,  0.7941],\n",
      "        [ 0.4802,  0.3827,  0.5166,  0.5904]], grad_fn=<TanhBackward0>), tensor([[-0.1787,  0.6622, -0.2633,  0.0250],\n",
      "        [ 0.2145,  0.1109, -0.8455, -0.4656],\n",
      "        [ 0.2676,  0.4616,  0.0830,  0.1422],\n",
      "        [ 0.5184, -0.1549, -0.6986, -0.4935]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3735, -0.5983, -0.1478,  0.4402],\n",
      "        [ 0.7077,  0.0673,  0.4283,  0.0607],\n",
      "        [ 0.0417, -0.3427, -0.0369,  0.7946],\n",
      "        [ 0.4867,  0.3805,  0.5153,  0.5864]], grad_fn=<TanhBackward0>), tensor([[-0.1818,  0.6704, -0.2703,  0.0215],\n",
      "        [ 0.2125,  0.1294, -0.8493, -0.4627],\n",
      "        [ 0.2631,  0.4621,  0.0716,  0.1296],\n",
      "        [ 0.5167, -0.1525, -0.7063, -0.5007]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3715, -0.6038, -0.1547,  0.4331],\n",
      "        [ 0.7077,  0.0544,  0.4205,  0.0448],\n",
      "        [ 0.0479, -0.3408, -0.0357,  0.7952],\n",
      "        [ 0.4932,  0.3787,  0.5142,  0.5827]], grad_fn=<TanhBackward0>), tensor([[-0.1846,  0.6785, -0.2768,  0.0183],\n",
      "        [ 0.2108,  0.1480, -0.8529, -0.4594],\n",
      "        [ 0.2588,  0.4624,  0.0604,  0.1172],\n",
      "        [ 0.5152, -0.1506, -0.7137, -0.5075]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3695, -0.6092, -0.1615,  0.4261],\n",
      "        [ 0.7078,  0.0420,  0.4126,  0.0293],\n",
      "        [ 0.0541, -0.3386, -0.0345,  0.7959],\n",
      "        [ 0.4998,  0.3774,  0.5133,  0.5794]], grad_fn=<TanhBackward0>), tensor([[-0.1873,  0.6866, -0.2831,  0.0154],\n",
      "        [ 0.2094,  0.1666, -0.8563, -0.4558],\n",
      "        [ 0.2545,  0.4625,  0.0495,  0.1049],\n",
      "        [ 0.5139, -0.1493, -0.7207, -0.5141]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3675, -0.6144, -0.1682,  0.4193],\n",
      "        [ 0.7079,  0.0301,  0.4049,  0.0144],\n",
      "        [ 0.0603, -0.3363, -0.0331,  0.7967],\n",
      "        [ 0.5063,  0.3766,  0.5126,  0.5765]], grad_fn=<TanhBackward0>), tensor([[-0.1898,  0.6946, -0.2890,  0.0129],\n",
      "        [ 0.2084,  0.1851, -0.8594, -0.4519],\n",
      "        [ 0.2504,  0.4623,  0.0387,  0.0929],\n",
      "        [ 0.5128, -0.1486, -0.7272, -0.5204]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 3.6543e-01, -6.1937e-01, -1.7493e-01,  4.1261e-01],\n",
      "        [ 7.0802e-01,  1.8602e-02,  3.9728e-01,  8.3894e-05],\n",
      "        [ 6.6329e-02, -3.3367e-01, -3.1707e-02,  7.9768e-01],\n",
      "        [ 5.1278e-01,  3.7621e-01,  5.1201e-01,  5.7405e-01]],\n",
      "       grad_fn=<TanhBackward0>), tensor([[-0.1922,  0.7026, -0.2946,  0.0106],\n",
      "        [ 0.2078,  0.2035, -0.8623, -0.4479],\n",
      "        [ 0.2465,  0.4620,  0.0283,  0.0810],\n",
      "        [ 0.5119, -0.1486, -0.7333, -0.5263]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3634, -0.6242, -0.1816,  0.4061],\n",
      "        [ 0.7082,  0.0077,  0.3898, -0.0136],\n",
      "        [ 0.0723, -0.3309, -0.0303,  0.7987],\n",
      "        [ 0.5192,  0.3763,  0.5116,  0.5720]], grad_fn=<TanhBackward0>), tensor([[-0.1945,  0.7104, -0.2999,  0.0086],\n",
      "        [ 0.2075,  0.2215, -0.8650, -0.4436],\n",
      "        [ 0.2427,  0.4615,  0.0182,  0.0695],\n",
      "        [ 0.5112, -0.1492, -0.7391, -0.5320]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3613, -0.6289, -0.1882,  0.3998],\n",
      "        [ 0.7085, -0.0027,  0.3825, -0.0266],\n",
      "        [ 0.0781, -0.3280, -0.0288,  0.7998],\n",
      "        [ 0.5255,  0.3768,  0.5114,  0.5704]], grad_fn=<TanhBackward0>), tensor([[-0.1965,  0.7181, -0.3049,  0.0068],\n",
      "        [ 0.2075,  0.2392, -0.8675, -0.4392],\n",
      "        [ 0.2391,  0.4609,  0.0084,  0.0582],\n",
      "        [ 0.5108, -0.1505, -0.7445, -0.5374]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3592, -0.6334, -0.1947,  0.3936],\n",
      "        [ 0.7088, -0.0125,  0.3753, -0.0390],\n",
      "        [ 0.0837, -0.3250, -0.0273,  0.8011],\n",
      "        [ 0.5318,  0.3777,  0.5113,  0.5693]], grad_fn=<TanhBackward0>), tensor([[-0.1985,  0.7257, -0.3096,  0.0052],\n",
      "        [ 0.2079,  0.2566, -0.8698, -0.4347],\n",
      "        [ 0.2357,  0.4602, -0.0009,  0.0473],\n",
      "        [ 0.5106, -0.1524, -0.7495, -0.5424]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3571, -0.6377, -0.2012,  0.3877],\n",
      "        [ 0.7091, -0.0217,  0.3684, -0.0506],\n",
      "        [ 0.0891, -0.3219, -0.0260,  0.8023],\n",
      "        [ 0.5379,  0.3789,  0.5114,  0.5685]], grad_fn=<TanhBackward0>), tensor([[-0.2004,  0.7332, -0.3142,  0.0037],\n",
      "        [ 0.2086,  0.2734, -0.8721, -0.4302],\n",
      "        [ 0.2324,  0.4594, -0.0098,  0.0367],\n",
      "        [ 0.5107, -0.1550, -0.7541, -0.5471]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3549, -0.6419, -0.2077,  0.3819],\n",
      "        [ 0.7094, -0.0304,  0.3616, -0.0616],\n",
      "        [ 0.0943, -0.3188, -0.0246,  0.8037],\n",
      "        [ 0.5438,  0.3805,  0.5115,  0.5682]], grad_fn=<TanhBackward0>), tensor([[-0.2022,  0.7405, -0.3185,  0.0024],\n",
      "        [ 0.2096,  0.2899, -0.8741, -0.4255],\n",
      "        [ 0.2294,  0.4586, -0.0183,  0.0265],\n",
      "        [ 0.5110, -0.1581, -0.7583, -0.5516]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3527, -0.6459, -0.2140,  0.3764],\n",
      "        [ 0.7098, -0.0386,  0.3550, -0.0719],\n",
      "        [ 0.0991, -0.3156, -0.0234,  0.8050],\n",
      "        [ 0.5496,  0.3824,  0.5118,  0.5682]], grad_fn=<TanhBackward0>), tensor([[-0.2039,  0.7477, -0.3226,  0.0012],\n",
      "        [ 0.2109,  0.3058, -0.8761, -0.4209],\n",
      "        [ 0.2264,  0.4578, -0.0262,  0.0167],\n",
      "        [ 0.5115, -0.1617, -0.7623, -0.5556]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3504, -0.6498, -0.2204,  0.3710],\n",
      "        [ 0.7102, -0.0463,  0.3486, -0.0816],\n",
      "        [ 0.1037, -0.3125, -0.0224,  0.8064],\n",
      "        [ 0.5552,  0.3845,  0.5121,  0.5685]], grad_fn=<TanhBackward0>), tensor([[-2.0554e-01,  7.5474e-01, -3.2664e-01,  2.4073e-05],\n",
      "        [ 2.1251e-01,  3.2121e-01, -8.7795e-01, -4.1625e-01],\n",
      "        [ 2.2368e-01,  4.5702e-01, -3.3585e-02,  7.3551e-03],\n",
      "        [ 5.1233e-01, -1.6571e-01, -7.6581e-01, -5.5932e-01]],\n",
      "       grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3480, -0.6536, -0.2267,  0.3658],\n",
      "        [ 0.7106, -0.0535,  0.3424, -0.0907],\n",
      "        [ 0.1079, -0.3095, -0.0215,  0.8078],\n",
      "        [ 0.5605,  0.3868,  0.5124,  0.5691]], grad_fn=<TanhBackward0>), tensor([[-0.2072,  0.7616, -0.3305, -0.0011],\n",
      "        [ 0.2143,  0.3361, -0.8797, -0.4116],\n",
      "        [ 0.2211,  0.4564, -0.0404, -0.0016],\n",
      "        [ 0.5134, -0.1701, -0.7690, -0.5627]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3456, -0.6572, -0.2329,  0.3607],\n",
      "        [ 0.7110, -0.0603,  0.3363, -0.0992],\n",
      "        [ 0.1118, -0.3065, -0.0207,  0.8092],\n",
      "        [ 0.5656,  0.3892,  0.5128,  0.5700]], grad_fn=<TanhBackward0>), tensor([[-0.2088,  0.7684, -0.3342, -0.0022],\n",
      "        [ 0.2163,  0.3506, -0.8814, -0.4070],\n",
      "        [ 0.2186,  0.4558, -0.0467, -0.0100],\n",
      "        [ 0.5147, -0.1749, -0.7719, -0.5656]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3430, -0.6608, -0.2391,  0.3558],\n",
      "        [ 0.7114, -0.0667,  0.3304, -0.1072],\n",
      "        [ 0.1154, -0.3037, -0.0202,  0.8106],\n",
      "        [ 0.5705,  0.3917,  0.5131,  0.5711]], grad_fn=<TanhBackward0>), tensor([[-0.2105,  0.7750, -0.3379, -0.0034],\n",
      "        [ 0.2185,  0.3645, -0.8829, -0.4024],\n",
      "        [ 0.2163,  0.4554, -0.0524, -0.0180],\n",
      "        [ 0.5163, -0.1799, -0.7745, -0.5683]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3404, -0.6642, -0.2453,  0.3511],\n",
      "        [ 0.7117, -0.0726,  0.3247, -0.1147],\n",
      "        [ 0.1186, -0.3010, -0.0198,  0.8120],\n",
      "        [ 0.5752,  0.3944,  0.5135,  0.5724]], grad_fn=<TanhBackward0>), tensor([[-0.2122,  0.7815, -0.3414, -0.0046],\n",
      "        [ 0.2208,  0.3780, -0.8845, -0.3979],\n",
      "        [ 0.2141,  0.4553, -0.0575, -0.0256],\n",
      "        [ 0.5181, -0.1851, -0.7768, -0.5705]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3378, -0.6676, -0.2514,  0.3464],\n",
      "        [ 0.7121, -0.0783,  0.3191, -0.1217],\n",
      "        [ 0.1214, -0.2985, -0.0197,  0.8134],\n",
      "        [ 0.5796,  0.3970,  0.5138,  0.5739]], grad_fn=<TanhBackward0>), tensor([[-0.2139,  0.7878, -0.3449, -0.0059],\n",
      "        [ 0.2233,  0.3911, -0.8859, -0.3935],\n",
      "        [ 0.2121,  0.4553, -0.0621, -0.0327],\n",
      "        [ 0.5201, -0.1904, -0.7787, -0.5724]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3350, -0.6709, -0.2575,  0.3419],\n",
      "        [ 0.7124, -0.0836,  0.3137, -0.1283],\n",
      "        [ 0.1239, -0.2961, -0.0198,  0.8147],\n",
      "        [ 0.5837,  0.3997,  0.5141,  0.5754]], grad_fn=<TanhBackward0>), tensor([[-0.2157,  0.7940, -0.3484, -0.0073],\n",
      "        [ 0.2258,  0.4037, -0.8873, -0.3892],\n",
      "        [ 0.2102,  0.4556, -0.0660, -0.0394],\n",
      "        [ 0.5224, -0.1958, -0.7804, -0.5739]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3321, -0.6741, -0.2635,  0.3375],\n",
      "        [ 0.7127, -0.0886,  0.3084, -0.1344],\n",
      "        [ 0.1260, -0.2939, -0.0201,  0.8160],\n",
      "        [ 0.5876,  0.4024,  0.5143,  0.5771]], grad_fn=<TanhBackward0>), tensor([[-0.2175,  0.8000, -0.3518, -0.0089],\n",
      "        [ 0.2285,  0.4158, -0.8886, -0.3850],\n",
      "        [ 0.2084,  0.4561, -0.0695, -0.0457],\n",
      "        [ 0.5249, -0.2012, -0.7818, -0.5751]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3292, -0.6772, -0.2695,  0.3332],\n",
      "        [ 0.7129, -0.0933,  0.3032, -0.1403],\n",
      "        [ 0.1278, -0.2919, -0.0206,  0.8172],\n",
      "        [ 0.5913,  0.4051,  0.5145,  0.5789]], grad_fn=<TanhBackward0>), tensor([[-0.2195,  0.8058, -0.3553, -0.0106],\n",
      "        [ 0.2312,  0.4276, -0.8899, -0.3809],\n",
      "        [ 0.2068,  0.4568, -0.0723, -0.0517],\n",
      "        [ 0.5277, -0.2067, -0.7830, -0.5760]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3261, -0.6802, -0.2755,  0.3289],\n",
      "        [ 0.7131, -0.0978,  0.2982, -0.1457],\n",
      "        [ 0.1292, -0.2901, -0.0213,  0.8184],\n",
      "        [ 0.5947,  0.4077,  0.5146,  0.5807]], grad_fn=<TanhBackward0>), tensor([[-0.2215,  0.8115, -0.3587, -0.0125],\n",
      "        [ 0.2339,  0.4389, -0.8912, -0.3769],\n",
      "        [ 0.2052,  0.4578, -0.0747, -0.0573],\n",
      "        [ 0.5307, -0.2121, -0.7839, -0.5765]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3230, -0.6832, -0.2814,  0.3248],\n",
      "        [ 0.7133, -0.1020,  0.2933, -0.1509],\n",
      "        [ 0.1303, -0.2884, -0.0222,  0.8195],\n",
      "        [ 0.5980,  0.4103,  0.5147,  0.5826]], grad_fn=<TanhBackward0>), tensor([[-0.2236,  0.8170, -0.3622, -0.0147],\n",
      "        [ 0.2368,  0.4499, -0.8924, -0.3731],\n",
      "        [ 0.2038,  0.4591, -0.0765, -0.0626],\n",
      "        [ 0.5340, -0.2175, -0.7845, -0.5767]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3198, -0.6862, -0.2873,  0.3207],\n",
      "        [ 0.7135, -0.1060,  0.2884, -0.1558],\n",
      "        [ 0.1312, -0.2870, -0.0233,  0.8206],\n",
      "        [ 0.6010,  0.4128,  0.5147,  0.5845]], grad_fn=<TanhBackward0>), tensor([[-0.2258,  0.8224, -0.3657, -0.0170],\n",
      "        [ 0.2396,  0.4605, -0.8936, -0.3694],\n",
      "        [ 0.2025,  0.4606, -0.0779, -0.0676],\n",
      "        [ 0.5375, -0.2227, -0.7850, -0.5767]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3166, -0.6890, -0.2931,  0.3167],\n",
      "        [ 0.7136, -0.1098,  0.2837, -0.1605],\n",
      "        [ 0.1317, -0.2856, -0.0246,  0.8217],\n",
      "        [ 0.6038,  0.4153,  0.5147,  0.5864]], grad_fn=<TanhBackward0>), tensor([[-0.2281,  0.8276, -0.3693, -0.0197],\n",
      "        [ 0.2425,  0.4707, -0.8948, -0.3659],\n",
      "        [ 0.2013,  0.4623, -0.0788, -0.0724],\n",
      "        [ 0.5413, -0.2280, -0.7852, -0.5764]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3132, -0.6918, -0.2989,  0.3127],\n",
      "        [ 0.7136, -0.1135,  0.2791, -0.1649],\n",
      "        [ 0.1320, -0.2845, -0.0260,  0.8227],\n",
      "        [ 0.6064,  0.4177,  0.5147,  0.5883]], grad_fn=<TanhBackward0>), tensor([[-0.2306,  0.8326, -0.3729, -0.0225],\n",
      "        [ 0.2455,  0.4806, -0.8959, -0.3625],\n",
      "        [ 0.2002,  0.4642, -0.0794, -0.0770],\n",
      "        [ 0.5452, -0.2331, -0.7853, -0.5758]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3098, -0.6946, -0.3046,  0.3088],\n",
      "        [ 0.7137, -0.1170,  0.2746, -0.1691],\n",
      "        [ 0.1320, -0.2835, -0.0275,  0.8236],\n",
      "        [ 0.6088,  0.4201,  0.5146,  0.5902]], grad_fn=<TanhBackward0>), tensor([[-0.2331,  0.8375, -0.3765, -0.0256],\n",
      "        [ 0.2484,  0.4902, -0.8970, -0.3593],\n",
      "        [ 0.1993,  0.4663, -0.0795, -0.0813],\n",
      "        [ 0.5494, -0.2381, -0.7851, -0.5750]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3064, -0.6972, -0.3103,  0.3049],\n",
      "        [ 0.7137, -0.1203,  0.2702, -0.1731],\n",
      "        [ 0.1318, -0.2826, -0.0292,  0.8245],\n",
      "        [ 0.6111,  0.4224,  0.5144,  0.5921]], grad_fn=<TanhBackward0>), tensor([[-0.2357,  0.8422, -0.3802, -0.0290],\n",
      "        [ 0.2514,  0.4994, -0.8982, -0.3563],\n",
      "        [ 0.1984,  0.4685, -0.0793, -0.0856],\n",
      "        [ 0.5539, -0.2431, -0.7848, -0.5740]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.3029, -0.6999, -0.3159,  0.3011],\n",
      "        [ 0.7136, -0.1234,  0.2658, -0.1770],\n",
      "        [ 0.1314, -0.2819, -0.0309,  0.8254],\n",
      "        [ 0.6132,  0.4246,  0.5142,  0.5940]], grad_fn=<TanhBackward0>), tensor([[-0.2383,  0.8467, -0.3840, -0.0327],\n",
      "        [ 0.2545,  0.5084, -0.8992, -0.3535],\n",
      "        [ 0.1977,  0.4709, -0.0788, -0.0897],\n",
      "        [ 0.5585, -0.2479, -0.7844, -0.5728]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2994, -0.7024, -0.3214,  0.2974],\n",
      "        [ 0.7136, -0.1265,  0.2616, -0.1807],\n",
      "        [ 0.1309, -0.2812, -0.0328,  0.8262],\n",
      "        [ 0.6151,  0.4268,  0.5140,  0.5958]], grad_fn=<TanhBackward0>), tensor([[-0.2411,  0.8511, -0.3878, -0.0366],\n",
      "        [ 0.2575,  0.5170, -0.9003, -0.3508],\n",
      "        [ 0.1971,  0.4735, -0.0780, -0.0937],\n",
      "        [ 0.5634, -0.2527, -0.7838, -0.5714]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2958, -0.7050, -0.3268,  0.2937],\n",
      "        [ 0.7135, -0.1294,  0.2575, -0.1842],\n",
      "        [ 0.1301, -0.2807, -0.0348,  0.8270],\n",
      "        [ 0.6170,  0.4289,  0.5138,  0.5977]], grad_fn=<TanhBackward0>), tensor([[-0.2439,  0.8553, -0.3917, -0.0408],\n",
      "        [ 0.2606,  0.5253, -0.9014, -0.3483],\n",
      "        [ 0.1966,  0.4761, -0.0770, -0.0976],\n",
      "        [ 0.5684, -0.2574, -0.7830, -0.5699]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2922, -0.7074, -0.3322,  0.2900],\n",
      "        [ 0.7133, -0.1321,  0.2534, -0.1876],\n",
      "        [ 0.1292, -0.2803, -0.0368,  0.8277],\n",
      "        [ 0.6187,  0.4310,  0.5136,  0.5995]], grad_fn=<TanhBackward0>), tensor([[-0.2469,  0.8594, -0.3956, -0.0453],\n",
      "        [ 0.2638,  0.5334, -0.9024, -0.3460],\n",
      "        [ 0.1962,  0.4788, -0.0757, -0.1015],\n",
      "        [ 0.5737, -0.2621, -0.7821, -0.5682]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2886, -0.7098, -0.3375,  0.2863],\n",
      "        [ 0.7132, -0.1348,  0.2495, -0.1909],\n",
      "        [ 0.1282, -0.2799, -0.0388,  0.8284],\n",
      "        [ 0.6203,  0.4330,  0.5133,  0.6012]], grad_fn=<TanhBackward0>), tensor([[-0.2498,  0.8633, -0.3996, -0.0500],\n",
      "        [ 0.2670,  0.5411, -0.9035, -0.3438],\n",
      "        [ 0.1960,  0.4816, -0.0742, -0.1053],\n",
      "        [ 0.5791, -0.2667, -0.7811, -0.5664]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2850, -0.7122, -0.3427,  0.2827],\n",
      "        [ 0.7130, -0.1374,  0.2456, -0.1941],\n",
      "        [ 0.1270, -0.2796, -0.0409,  0.8290],\n",
      "        [ 0.6218,  0.4350,  0.5131,  0.6030]], grad_fn=<TanhBackward0>), tensor([[-0.2529,  0.8671, -0.4037, -0.0550],\n",
      "        [ 0.2702,  0.5487, -0.9045, -0.3418],\n",
      "        [ 0.1959,  0.4844, -0.0725, -0.1091],\n",
      "        [ 0.5847, -0.2712, -0.7800, -0.5644]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2813, -0.7145, -0.3478,  0.2792],\n",
      "        [ 0.7128, -0.1398,  0.2418, -0.1971],\n",
      "        [ 0.1258, -0.2794, -0.0431,  0.8297],\n",
      "        [ 0.6232,  0.4369,  0.5128,  0.6047]], grad_fn=<TanhBackward0>), tensor([[-0.2560,  0.8707, -0.4078, -0.0602],\n",
      "        [ 0.2735,  0.5559, -0.9055, -0.3399],\n",
      "        [ 0.1958,  0.4872, -0.0707, -0.1130],\n",
      "        [ 0.5905, -0.2757, -0.7788, -0.5624]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2777, -0.7167, -0.3529,  0.2757],\n",
      "        [ 0.7126, -0.1422,  0.2381, -0.2001],\n",
      "        [ 0.1244, -0.2793, -0.0452,  0.8302],\n",
      "        [ 0.6245,  0.4388,  0.5126,  0.6064]], grad_fn=<TanhBackward0>), tensor([[-0.2591,  0.8742, -0.4119, -0.0656],\n",
      "        [ 0.2769,  0.5629, -0.9065, -0.3382],\n",
      "        [ 0.1959,  0.4900, -0.0687, -0.1168],\n",
      "        [ 0.5964, -0.2802, -0.7775, -0.5602]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2741, -0.7189, -0.3578,  0.2722],\n",
      "        [ 0.7124, -0.1445,  0.2345, -0.2029],\n",
      "        [ 0.1230, -0.2792, -0.0474,  0.8308],\n",
      "        [ 0.6258,  0.4407,  0.5123,  0.6080]], grad_fn=<TanhBackward0>), tensor([[-0.2622,  0.8776, -0.4161, -0.0712],\n",
      "        [ 0.2803,  0.5697, -0.9075, -0.3366],\n",
      "        [ 0.1962,  0.4929, -0.0666, -0.1207],\n",
      "        [ 0.6025, -0.2846, -0.7761, -0.5580]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2704, -0.7210, -0.3627,  0.2687],\n",
      "        [ 0.7122, -0.1467,  0.2309, -0.2057],\n",
      "        [ 0.1215, -0.2791, -0.0495,  0.8313],\n",
      "        [ 0.6270,  0.4425,  0.5121,  0.6096]], grad_fn=<TanhBackward0>), tensor([[-0.2654,  0.8808, -0.4202, -0.0771],\n",
      "        [ 0.2837,  0.5762, -0.9085, -0.3352],\n",
      "        [ 0.1965,  0.4957, -0.0643, -0.1246],\n",
      "        [ 0.6087, -0.2890, -0.7747, -0.5557]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2668, -0.7231, -0.3674,  0.2653],\n",
      "        [ 0.7119, -0.1488,  0.2275, -0.2084],\n",
      "        [ 0.1200, -0.2791, -0.0517,  0.8319],\n",
      "        [ 0.6281,  0.4443,  0.5118,  0.6112]], grad_fn=<TanhBackward0>), tensor([[-0.2687,  0.8839, -0.4244, -0.0831],\n",
      "        [ 0.2873,  0.5826, -0.9095, -0.3338],\n",
      "        [ 0.1969,  0.4985, -0.0620, -0.1285],\n",
      "        [ 0.6150, -0.2935, -0.7731, -0.5533]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2632, -0.7252, -0.3721,  0.2620],\n",
      "        [ 0.7117, -0.1508,  0.2241, -0.2110],\n",
      "        [ 0.1184, -0.2791, -0.0538,  0.8324],\n",
      "        [ 0.6291,  0.4461,  0.5116,  0.6127]], grad_fn=<TanhBackward0>), tensor([[-0.2719,  0.8868, -0.4287, -0.0893],\n",
      "        [ 0.2908,  0.5887, -0.9104, -0.3326],\n",
      "        [ 0.1974,  0.5012, -0.0596, -0.1325],\n",
      "        [ 0.6213, -0.2979, -0.7716, -0.5509]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2596, -0.7271, -0.3767,  0.2587],\n",
      "        [ 0.7114, -0.1528,  0.2208, -0.2135],\n",
      "        [ 0.1167, -0.2791, -0.0560,  0.8328],\n",
      "        [ 0.6301,  0.4478,  0.5114,  0.6143]], grad_fn=<TanhBackward0>), tensor([[-0.2752,  0.8897, -0.4329, -0.0956],\n",
      "        [ 0.2945,  0.5946, -0.9114, -0.3315],\n",
      "        [ 0.1981,  0.5039, -0.0572, -0.1365],\n",
      "        [ 0.6278, -0.3023, -0.7699, -0.5485]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2560, -0.7291, -0.3811,  0.2554],\n",
      "        [ 0.7111, -0.1547,  0.2175, -0.2160],\n",
      "        [ 0.1151, -0.2792, -0.0581,  0.8333],\n",
      "        [ 0.6311,  0.4495,  0.5112,  0.6157]], grad_fn=<TanhBackward0>), tensor([[-0.2784,  0.8924, -0.4371, -0.1020],\n",
      "        [ 0.2981,  0.6003, -0.9123, -0.3305],\n",
      "        [ 0.1988,  0.5066, -0.0546, -0.1405],\n",
      "        [ 0.6343, -0.3067, -0.7682, -0.5460]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2524, -0.7310, -0.3855,  0.2522],\n",
      "        [ 0.7108, -0.1565,  0.2144, -0.2183],\n",
      "        [ 0.1134, -0.2792, -0.0602,  0.8337],\n",
      "        [ 0.6320,  0.4512,  0.5110,  0.6172]], grad_fn=<TanhBackward0>), tensor([[-0.2817,  0.8951, -0.4413, -0.1086],\n",
      "        [ 0.3019,  0.6058, -0.9132, -0.3296],\n",
      "        [ 0.1996,  0.5091, -0.0521, -0.1446],\n",
      "        [ 0.6409, -0.3111, -0.7665, -0.5435]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2489, -0.7328, -0.3898,  0.2490],\n",
      "        [ 0.7106, -0.1582,  0.2113, -0.2207],\n",
      "        [ 0.1117, -0.2793, -0.0622,  0.8341],\n",
      "        [ 0.6328,  0.4528,  0.5108,  0.6186]], grad_fn=<TanhBackward0>), tensor([[-0.2850,  0.8976, -0.4455, -0.1152],\n",
      "        [ 0.3057,  0.6112, -0.9141, -0.3288],\n",
      "        [ 0.2005,  0.5117, -0.0495, -0.1488],\n",
      "        [ 0.6475, -0.3155, -0.7647, -0.5409]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2454, -0.7346, -0.3940,  0.2459],\n",
      "        [ 0.7103, -0.1599,  0.2083, -0.2229],\n",
      "        [ 0.1099, -0.2794, -0.0642,  0.8345],\n",
      "        [ 0.6337,  0.4544,  0.5107,  0.6200]], grad_fn=<TanhBackward0>), tensor([[-0.2882,  0.9000, -0.4497, -0.1220],\n",
      "        [ 0.3095,  0.6163, -0.9150, -0.3280],\n",
      "        [ 0.2015,  0.5141, -0.0469, -0.1529],\n",
      "        [ 0.6541, -0.3199, -0.7629, -0.5384]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [100/1000], Loss: 0.13553008437156677\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2420, -0.7364, -0.3981,  0.2428],\n",
      "        [ 0.7100, -0.1616,  0.2054, -0.2251],\n",
      "        [ 0.1082, -0.2796, -0.0662,  0.8349],\n",
      "        [ 0.6345,  0.4560,  0.5105,  0.6214]], grad_fn=<TanhBackward0>), tensor([[-0.2915,  0.9023, -0.4538, -0.1287],\n",
      "        [ 0.3134,  0.6213, -0.9159, -0.3273],\n",
      "        [ 0.2026,  0.5165, -0.0442, -0.1572],\n",
      "        [ 0.6607, -0.3244, -0.7611, -0.5359]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2386, -0.7381, -0.4021,  0.2398],\n",
      "        [ 0.7097, -0.1632,  0.2026, -0.2272],\n",
      "        [ 0.1064, -0.2797, -0.0682,  0.8352],\n",
      "        [ 0.6352,  0.4575,  0.5104,  0.6227]], grad_fn=<TanhBackward0>), tensor([[-0.2947,  0.9046, -0.4580, -0.1355],\n",
      "        [ 0.3173,  0.6261, -0.9167, -0.3267],\n",
      "        [ 0.2037,  0.5188, -0.0416, -0.1614],\n",
      "        [ 0.6673, -0.3288, -0.7592, -0.5333]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2352, -0.7397, -0.4060,  0.2368],\n",
      "        [ 0.7094, -0.1647,  0.1998, -0.2293],\n",
      "        [ 0.1047, -0.2799, -0.0701,  0.8356],\n",
      "        [ 0.6359,  0.4590,  0.5103,  0.6240]], grad_fn=<TanhBackward0>), tensor([[-0.2979,  0.9067, -0.4620, -0.1424],\n",
      "        [ 0.3212,  0.6308, -0.9176, -0.3261],\n",
      "        [ 0.2050,  0.5211, -0.0389, -0.1657],\n",
      "        [ 0.6739, -0.3332, -0.7574, -0.5308]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2319, -0.7413, -0.4098,  0.2339],\n",
      "        [ 0.7091, -0.1662,  0.1971, -0.2313],\n",
      "        [ 0.1029, -0.2800, -0.0720,  0.8359],\n",
      "        [ 0.6366,  0.4605,  0.5102,  0.6253]], grad_fn=<TanhBackward0>), tensor([[-0.3011,  0.9088, -0.4661, -0.1492],\n",
      "        [ 0.3252,  0.6353, -0.9184, -0.3256],\n",
      "        [ 0.2062,  0.5232, -0.0363, -0.1700],\n",
      "        [ 0.6805, -0.3376, -0.7555, -0.5283]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2286, -0.7429, -0.4136,  0.2310],\n",
      "        [ 0.7088, -0.1677,  0.1944, -0.2333],\n",
      "        [ 0.1012, -0.2802, -0.0739,  0.8363],\n",
      "        [ 0.6372,  0.4620,  0.5101,  0.6265]], grad_fn=<TanhBackward0>), tensor([[-0.3043,  0.9108, -0.4700, -0.1560],\n",
      "        [ 0.3292,  0.6397, -0.9192, -0.3250],\n",
      "        [ 0.2076,  0.5253, -0.0336, -0.1744],\n",
      "        [ 0.6870, -0.3420, -0.7536, -0.5259]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2254, -0.7445, -0.4172,  0.2282],\n",
      "        [ 0.7085, -0.1691,  0.1919, -0.2352],\n",
      "        [ 0.0994, -0.2804, -0.0757,  0.8366],\n",
      "        [ 0.6379,  0.4634,  0.5100,  0.6277]], grad_fn=<TanhBackward0>), tensor([[-0.3074,  0.9127, -0.4740, -0.1628],\n",
      "        [ 0.3332,  0.6439, -0.9200, -0.3245],\n",
      "        [ 0.2090,  0.5273, -0.0310, -0.1787],\n",
      "        [ 0.6934, -0.3464, -0.7517, -0.5234]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2222, -0.7460, -0.4207,  0.2255],\n",
      "        [ 0.7082, -0.1704,  0.1894, -0.2370],\n",
      "        [ 0.0977, -0.2806, -0.0775,  0.8369],\n",
      "        [ 0.6385,  0.4647,  0.5099,  0.6289]], grad_fn=<TanhBackward0>), tensor([[-0.3106,  0.9145, -0.4778, -0.1696],\n",
      "        [ 0.3373,  0.6480, -0.9208, -0.3241],\n",
      "        [ 0.2104,  0.5293, -0.0284, -0.1831],\n",
      "        [ 0.6997, -0.3508, -0.7499, -0.5210]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2191, -0.7474, -0.4242,  0.2228],\n",
      "        [ 0.7079, -0.1717,  0.1869, -0.2388],\n",
      "        [ 0.0960, -0.2808, -0.0792,  0.8372],\n",
      "        [ 0.6390,  0.4661,  0.5098,  0.6301]], grad_fn=<TanhBackward0>), tensor([[-0.3136,  0.9163, -0.4816, -0.1763],\n",
      "        [ 0.3413,  0.6520, -0.9216, -0.3236],\n",
      "        [ 0.2119,  0.5312, -0.0258, -0.1874],\n",
      "        [ 0.7060, -0.3552, -0.7480, -0.5186]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2160, -0.7488, -0.4275,  0.2201],\n",
      "        [ 0.7076, -0.1730,  0.1845, -0.2405],\n",
      "        [ 0.0943, -0.2810, -0.0809,  0.8375],\n",
      "        [ 0.6396,  0.4674,  0.5098,  0.6312]], grad_fn=<TanhBackward0>), tensor([[-0.3167,  0.9180, -0.4853, -0.1829],\n",
      "        [ 0.3453,  0.6558, -0.9223, -0.3232],\n",
      "        [ 0.2134,  0.5330, -0.0232, -0.1918],\n",
      "        [ 0.7122, -0.3596, -0.7461, -0.5163]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2130, -0.7502, -0.4308,  0.2175],\n",
      "        [ 0.7073, -0.1743,  0.1822, -0.2422],\n",
      "        [ 0.0926, -0.2812, -0.0826,  0.8377],\n",
      "        [ 0.6401,  0.4686,  0.5097,  0.6323]], grad_fn=<TanhBackward0>), tensor([[-0.3197,  0.9196, -0.4890, -0.1894],\n",
      "        [ 0.3494,  0.6595, -0.9231, -0.3227],\n",
      "        [ 0.2149,  0.5348, -0.0206, -0.1961],\n",
      "        [ 0.7182, -0.3639, -0.7443, -0.5140]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2100, -0.7515, -0.4340,  0.2150],\n",
      "        [ 0.7070, -0.1755,  0.1800, -0.2438],\n",
      "        [ 0.0909, -0.2815, -0.0843,  0.8380],\n",
      "        [ 0.6406,  0.4699,  0.5097,  0.6334]], grad_fn=<TanhBackward0>), tensor([[-0.3227,  0.9212, -0.4926, -0.1958],\n",
      "        [ 0.3534,  0.6631, -0.9238, -0.3223],\n",
      "        [ 0.2165,  0.5365, -0.0181, -0.2004],\n",
      "        [ 0.7242, -0.3682, -0.7425, -0.5118]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2071, -0.7528, -0.4371,  0.2126],\n",
      "        [ 0.7067, -0.1766,  0.1778, -0.2454],\n",
      "        [ 0.0892, -0.2817, -0.0859,  0.8382],\n",
      "        [ 0.6411,  0.4711,  0.5096,  0.6345]], grad_fn=<TanhBackward0>), tensor([[-0.3256,  0.9227, -0.4961, -0.2022],\n",
      "        [ 0.3574,  0.6666, -0.9245, -0.3218],\n",
      "        [ 0.2180,  0.5382, -0.0156, -0.2048],\n",
      "        [ 0.7300, -0.3724, -0.7407, -0.5096]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2042, -0.7541, -0.4401,  0.2101],\n",
      "        [ 0.7064, -0.1778,  0.1757, -0.2470],\n",
      "        [ 0.0876, -0.2820, -0.0875,  0.8385],\n",
      "        [ 0.6415,  0.4722,  0.5096,  0.6355]], grad_fn=<TanhBackward0>), tensor([[-0.3285,  0.9241, -0.4995, -0.2084],\n",
      "        [ 0.3614,  0.6700, -0.9252, -0.3214],\n",
      "        [ 0.2196,  0.5398, -0.0131, -0.2090],\n",
      "        [ 0.7357, -0.3766, -0.7389, -0.5075]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.2014, -0.7553, -0.4430,  0.2078],\n",
      "        [ 0.7062, -0.1789,  0.1736, -0.2484],\n",
      "        [ 0.0860, -0.2822, -0.0890,  0.8387],\n",
      "        [ 0.6419,  0.4733,  0.5095,  0.6365]], grad_fn=<TanhBackward0>), tensor([[-0.3314,  0.9255, -0.5028, -0.2145],\n",
      "        [ 0.3654,  0.6733, -0.9258, -0.3209],\n",
      "        [ 0.2212,  0.5413, -0.0107, -0.2133],\n",
      "        [ 0.7413, -0.3808, -0.7372, -0.5054]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1987, -0.7565, -0.4459,  0.2055],\n",
      "        [ 0.7059, -0.1799,  0.1716, -0.2499],\n",
      "        [ 0.0843, -0.2825, -0.0905,  0.8390],\n",
      "        [ 0.6423,  0.4744,  0.5095,  0.6375]], grad_fn=<TanhBackward0>), tensor([[-0.3342,  0.9269, -0.5061, -0.2205],\n",
      "        [ 0.3693,  0.6764, -0.9265, -0.3205],\n",
      "        [ 0.2228,  0.5428, -0.0083, -0.2175],\n",
      "        [ 0.7468, -0.3849, -0.7355, -0.5034]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1960, -0.7577, -0.4486,  0.2033],\n",
      "        [ 0.7056, -0.1810,  0.1696, -0.2513],\n",
      "        [ 0.0827, -0.2828, -0.0920,  0.8392],\n",
      "        [ 0.6427,  0.4755,  0.5094,  0.6384]], grad_fn=<TanhBackward0>), tensor([[-0.3370,  0.9282, -0.5093, -0.2263],\n",
      "        [ 0.3732,  0.6795, -0.9271, -0.3200],\n",
      "        [ 0.2244,  0.5443, -0.0059, -0.2217],\n",
      "        [ 0.7521, -0.3890, -0.7338, -0.5014]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1934, -0.7588, -0.4513,  0.2011],\n",
      "        [ 0.7054, -0.1820,  0.1677, -0.2526],\n",
      "        [ 0.0812, -0.2831, -0.0935,  0.8394],\n",
      "        [ 0.6431,  0.4765,  0.5094,  0.6393]], grad_fn=<TanhBackward0>), tensor([[-0.3397,  0.9294, -0.5124, -0.2320],\n",
      "        [ 0.3771,  0.6825, -0.9277, -0.3195],\n",
      "        [ 0.2260,  0.5457, -0.0035, -0.2259],\n",
      "        [ 0.7573, -0.3930, -0.7321, -0.4995]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1908, -0.7599, -0.4539,  0.1990],\n",
      "        [ 0.7051, -0.1830,  0.1659, -0.2539],\n",
      "        [ 0.0796, -0.2834, -0.0949,  0.8396],\n",
      "        [ 0.6434,  0.4774,  0.5094,  0.6402]], grad_fn=<TanhBackward0>), tensor([[-0.3424,  0.9306, -0.5154, -0.2376],\n",
      "        [ 0.3809,  0.6854, -0.9283, -0.3190],\n",
      "        [ 0.2276,  0.5471, -0.0012, -0.2300],\n",
      "        [ 0.7623, -0.3969, -0.7305, -0.4976]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1883, -0.7610, -0.4565,  0.1969],\n",
      "        [ 0.7049, -0.1839,  0.1641, -0.2552],\n",
      "        [ 0.0781, -0.2837, -0.0963,  0.8398],\n",
      "        [ 0.6438,  0.4784,  0.5093,  0.6411]], grad_fn=<TanhBackward0>), tensor([[-0.3450,  0.9317, -0.5183, -0.2430],\n",
      "        [ 0.3847,  0.6882, -0.9289, -0.3184],\n",
      "        [ 0.2292,  0.5484,  0.0010, -0.2340],\n",
      "        [ 0.7672, -0.4008, -0.7289, -0.4958]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1858, -0.7620, -0.4589,  0.1949],\n",
      "        [ 0.7046, -0.1849,  0.1623, -0.2564],\n",
      "        [ 0.0765, -0.2840, -0.0977,  0.8400],\n",
      "        [ 0.6441,  0.4793,  0.5093,  0.6420]], grad_fn=<TanhBackward0>), tensor([[-0.3476,  0.9329, -0.5211, -0.2483],\n",
      "        [ 0.3884,  0.6909, -0.9295, -0.3179],\n",
      "        [ 0.2307,  0.5497,  0.0033, -0.2380],\n",
      "        [ 0.7719, -0.4046, -0.7274, -0.4941]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1834, -0.7630, -0.4613,  0.1929],\n",
      "        [ 0.7044, -0.1858,  0.1606, -0.2576],\n",
      "        [ 0.0750, -0.2843, -0.0991,  0.8402],\n",
      "        [ 0.6444,  0.4801,  0.5092,  0.6428]], grad_fn=<TanhBackward0>), tensor([[-0.3501,  0.9339, -0.5239, -0.2534],\n",
      "        [ 0.3921,  0.6935, -0.9300, -0.3173],\n",
      "        [ 0.2323,  0.5510,  0.0055, -0.2419],\n",
      "        [ 0.7766, -0.4083, -0.7259, -0.4924]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1811, -0.7640, -0.4636,  0.1910],\n",
      "        [ 0.7041, -0.1866,  0.1590, -0.2587],\n",
      "        [ 0.0736, -0.2846, -0.1004,  0.8404],\n",
      "        [ 0.6446,  0.4810,  0.5092,  0.6436]], grad_fn=<TanhBackward0>), tensor([[-0.3526,  0.9349, -0.5266, -0.2584],\n",
      "        [ 0.3957,  0.6960, -0.9306, -0.3167],\n",
      "        [ 0.2338,  0.5522,  0.0076, -0.2458],\n",
      "        [ 0.7810, -0.4120, -0.7244, -0.4908]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1788, -0.7650, -0.4659,  0.1892],\n",
      "        [ 0.7039, -0.1875,  0.1574, -0.2598],\n",
      "        [ 0.0721, -0.2850, -0.1017,  0.8405],\n",
      "        [ 0.6449,  0.4818,  0.5091,  0.6443]], grad_fn=<TanhBackward0>), tensor([[-0.3550,  0.9359, -0.5292, -0.2633],\n",
      "        [ 0.3992,  0.6985, -0.9311, -0.3161],\n",
      "        [ 0.2353,  0.5534,  0.0097, -0.2496],\n",
      "        [ 0.7854, -0.4156, -0.7230, -0.4892]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1766, -0.7659, -0.4681,  0.1874],\n",
      "        [ 0.7037, -0.1883,  0.1559, -0.2609],\n",
      "        [ 0.0707, -0.2853, -0.1030,  0.8407],\n",
      "        [ 0.6451,  0.4825,  0.5090,  0.6451]], grad_fn=<TanhBackward0>), tensor([[-0.3574,  0.9369, -0.5317, -0.2679],\n",
      "        [ 0.4027,  0.7009, -0.9316, -0.3154],\n",
      "        [ 0.2368,  0.5546,  0.0118, -0.2534],\n",
      "        [ 0.7896, -0.4191, -0.7216, -0.4877]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1744, -0.7668, -0.4702,  0.1857],\n",
      "        [ 0.7035, -0.1891,  0.1543, -0.2619],\n",
      "        [ 0.0692, -0.2856, -0.1042,  0.8409],\n",
      "        [ 0.6453,  0.4833,  0.5090,  0.6458]], grad_fn=<TanhBackward0>), tensor([[-0.3597,  0.9378, -0.5341, -0.2725],\n",
      "        [ 0.4062,  0.7032, -0.9321, -0.3148],\n",
      "        [ 0.2383,  0.5557,  0.0139, -0.2571],\n",
      "        [ 0.7936, -0.4225, -0.7202, -0.4863]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1723, -0.7677, -0.4723,  0.1840],\n",
      "        [ 0.7032, -0.1899,  0.1529, -0.2629],\n",
      "        [ 0.0679, -0.2860, -0.1054,  0.8410],\n",
      "        [ 0.6455,  0.4840,  0.5089,  0.6465]], grad_fn=<TanhBackward0>), tensor([[-0.3620,  0.9387, -0.5365, -0.2769],\n",
      "        [ 0.4095,  0.7054, -0.9326, -0.3141],\n",
      "        [ 0.2397,  0.5568,  0.0159, -0.2607],\n",
      "        [ 0.7975, -0.4259, -0.7189, -0.4849]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1703, -0.7685, -0.4742,  0.1823],\n",
      "        [ 0.7030, -0.1907,  0.1515, -0.2638],\n",
      "        [ 0.0665, -0.2863, -0.1066,  0.8412],\n",
      "        [ 0.6457,  0.4846,  0.5088,  0.6472]], grad_fn=<TanhBackward0>), tensor([[-0.3642,  0.9395, -0.5388, -0.2812],\n",
      "        [ 0.4128,  0.7076, -0.9331, -0.3134],\n",
      "        [ 0.2411,  0.5579,  0.0179, -0.2643],\n",
      "        [ 0.8013, -0.4292, -0.7176, -0.4835]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1682, -0.7693, -0.4762,  0.1808],\n",
      "        [ 0.7028, -0.1914,  0.1501, -0.2647],\n",
      "        [ 0.0651, -0.2867, -0.1078,  0.8413],\n",
      "        [ 0.6459,  0.4853,  0.5088,  0.6479]], grad_fn=<TanhBackward0>), tensor([[-0.3664,  0.9403, -0.5410, -0.2853],\n",
      "        [ 0.4160,  0.7097, -0.9335, -0.3127],\n",
      "        [ 0.2425,  0.5590,  0.0198, -0.2678],\n",
      "        [ 0.8050, -0.4324, -0.7163, -0.4823]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1663, -0.7701, -0.4781,  0.1792],\n",
      "        [ 0.7026, -0.1921,  0.1488, -0.2656],\n",
      "        [ 0.0638, -0.2871, -0.1090,  0.8414],\n",
      "        [ 0.6461,  0.4859,  0.5087,  0.6485]], grad_fn=<TanhBackward0>), tensor([[-0.3686,  0.9411, -0.5431, -0.2893],\n",
      "        [ 0.4192,  0.7117, -0.9340, -0.3120],\n",
      "        [ 0.2438,  0.5601,  0.0217, -0.2712],\n",
      "        [ 0.8085, -0.4355, -0.7151, -0.4810]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1644, -0.7709, -0.4799,  0.1777],\n",
      "        [ 0.7024, -0.1928,  0.1475, -0.2665],\n",
      "        [ 0.0625, -0.2874, -0.1101,  0.8416],\n",
      "        [ 0.6462,  0.4865,  0.5086,  0.6491]], grad_fn=<TanhBackward0>), tensor([[-0.3706,  0.9419, -0.5451, -0.2931],\n",
      "        [ 0.4223,  0.7137, -0.9344, -0.3113],\n",
      "        [ 0.2452,  0.5611,  0.0235, -0.2745],\n",
      "        [ 0.8119, -0.4385, -0.7139, -0.4798]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1625, -0.7716, -0.4816,  0.1763],\n",
      "        [ 0.7022, -0.1935,  0.1462, -0.2673],\n",
      "        [ 0.0612, -0.2878, -0.1112,  0.8417],\n",
      "        [ 0.6463,  0.4870,  0.5085,  0.6497]], grad_fn=<TanhBackward0>), tensor([[-0.3727,  0.9426, -0.5471, -0.2969],\n",
      "        [ 0.4253,  0.7156, -0.9348, -0.3105],\n",
      "        [ 0.2465,  0.5621,  0.0254, -0.2778],\n",
      "        [ 0.8152, -0.4415, -0.7128, -0.4787]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1607, -0.7723, -0.4833,  0.1749],\n",
      "        [ 0.7020, -0.1942,  0.1450, -0.2681],\n",
      "        [ 0.0600, -0.2882, -0.1123,  0.8418],\n",
      "        [ 0.6465,  0.4876,  0.5084,  0.6503]], grad_fn=<TanhBackward0>), tensor([[-0.3747,  0.9433, -0.5491, -0.3004],\n",
      "        [ 0.4283,  0.7175, -0.9352, -0.3097],\n",
      "        [ 0.2477,  0.5631,  0.0271, -0.2810],\n",
      "        [ 0.8184, -0.4444, -0.7117, -0.4776]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1590, -0.7730, -0.4850,  0.1735],\n",
      "        [ 0.7019, -0.1948,  0.1438, -0.2689],\n",
      "        [ 0.0587, -0.2885, -0.1133,  0.8419],\n",
      "        [ 0.6466,  0.4881,  0.5083,  0.6509]], grad_fn=<TanhBackward0>), tensor([[-0.3766,  0.9440, -0.5509, -0.3039],\n",
      "        [ 0.4312,  0.7193, -0.9356, -0.3090],\n",
      "        [ 0.2490,  0.5640,  0.0289, -0.2842],\n",
      "        [ 0.8214, -0.4472, -0.7106, -0.4765]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1573, -0.7737, -0.4866,  0.1722],\n",
      "        [ 0.7017, -0.1954,  0.1427, -0.2696],\n",
      "        [ 0.0575, -0.2889, -0.1144,  0.8420],\n",
      "        [ 0.6467,  0.4886,  0.5082,  0.6514]], grad_fn=<TanhBackward0>), tensor([[-0.3785,  0.9447, -0.5527, -0.3073],\n",
      "        [ 0.4340,  0.7210, -0.9360, -0.3082],\n",
      "        [ 0.2502,  0.5650,  0.0306, -0.2872],\n",
      "        [ 0.8244, -0.4499, -0.7096, -0.4755]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1556, -0.7744, -0.4881,  0.1709],\n",
      "        [ 0.7015, -0.1960,  0.1416, -0.2703],\n",
      "        [ 0.0563, -0.2893, -0.1154,  0.8422],\n",
      "        [ 0.6468,  0.4890,  0.5082,  0.6520]], grad_fn=<TanhBackward0>), tensor([[-0.3803,  0.9453, -0.5544, -0.3105],\n",
      "        [ 0.4367,  0.7227, -0.9363, -0.3074],\n",
      "        [ 0.2513,  0.5659,  0.0323, -0.2902],\n",
      "        [ 0.8272, -0.4525, -0.7086, -0.4745]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1540, -0.7750, -0.4896,  0.1697],\n",
      "        [ 0.7013, -0.1966,  0.1405, -0.2710],\n",
      "        [ 0.0551, -0.2896, -0.1164,  0.8423],\n",
      "        [ 0.6469,  0.4895,  0.5081,  0.6525]], grad_fn=<TanhBackward0>), tensor([[-0.3821,  0.9459, -0.5561, -0.3136],\n",
      "        [ 0.4394,  0.7243, -0.9367, -0.3066],\n",
      "        [ 0.2525,  0.5668,  0.0339, -0.2932],\n",
      "        [ 0.8300, -0.4551, -0.7076, -0.4736]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1524, -0.7756, -0.4911,  0.1685],\n",
      "        [ 0.7012, -0.1972,  0.1395, -0.2716],\n",
      "        [ 0.0540, -0.2900, -0.1174,  0.8424],\n",
      "        [ 0.6469,  0.4899,  0.5080,  0.6530]], grad_fn=<TanhBackward0>), tensor([[-0.3839,  0.9465, -0.5577, -0.3166],\n",
      "        [ 0.4420,  0.7259, -0.9370, -0.3058],\n",
      "        [ 0.2536,  0.5677,  0.0355, -0.2960],\n",
      "        [ 0.8326, -0.4576, -0.7067, -0.4727]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1509, -0.7762, -0.4925,  0.1673],\n",
      "        [ 0.7010, -0.1977,  0.1385, -0.2723],\n",
      "        [ 0.0529, -0.2904, -0.1183,  0.8425],\n",
      "        [ 0.6470,  0.4903,  0.5079,  0.6535]], grad_fn=<TanhBackward0>), tensor([[-0.3856,  0.9470, -0.5592, -0.3195],\n",
      "        [ 0.4446,  0.7274, -0.9373, -0.3050],\n",
      "        [ 0.2547,  0.5686,  0.0371, -0.2988],\n",
      "        [ 0.8352, -0.4600, -0.7057, -0.4718]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1494, -0.7768, -0.4939,  0.1662],\n",
      "        [ 0.7009, -0.1982,  0.1375, -0.2729],\n",
      "        [ 0.0518, -0.2907, -0.1192,  0.8425],\n",
      "        [ 0.6471,  0.4907,  0.5078,  0.6539]], grad_fn=<TanhBackward0>), tensor([[-0.3872,  0.9476, -0.5607, -0.3223],\n",
      "        [ 0.4471,  0.7289, -0.9377, -0.3041],\n",
      "        [ 0.2557,  0.5695,  0.0386, -0.3015],\n",
      "        [ 0.8376, -0.4624, -0.7049, -0.4710]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1480, -0.7774, -0.4952,  0.1651],\n",
      "        [ 0.7007, -0.1987,  0.1366, -0.2735],\n",
      "        [ 0.0507, -0.2911, -0.1202,  0.8426],\n",
      "        [ 0.6471,  0.4911,  0.5077,  0.6544]], grad_fn=<TanhBackward0>), tensor([[-0.3888,  0.9481, -0.5622, -0.3249],\n",
      "        [ 0.4495,  0.7303, -0.9380, -0.3033],\n",
      "        [ 0.2568,  0.5703,  0.0401, -0.3042],\n",
      "        [ 0.8400, -0.4646, -0.7040, -0.4701]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1466, -0.7779, -0.4965,  0.1641],\n",
      "        [ 0.7006, -0.1992,  0.1357, -0.2740],\n",
      "        [ 0.0497, -0.2915, -0.1210,  0.8427],\n",
      "        [ 0.6472,  0.4914,  0.5076,  0.6548]], grad_fn=<TanhBackward0>), tensor([[-0.3904,  0.9486, -0.5635, -0.3275],\n",
      "        [ 0.4518,  0.7317, -0.9383, -0.3025],\n",
      "        [ 0.2578,  0.5711,  0.0416, -0.3068],\n",
      "        [ 0.8422, -0.4668, -0.7032, -0.4694]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1452, -0.7784, -0.4977,  0.1631],\n",
      "        [ 0.7004, -0.1997,  0.1348, -0.2746],\n",
      "        [ 0.0486, -0.2918, -0.1219,  0.8428],\n",
      "        [ 0.6472,  0.4918,  0.5075,  0.6552]], grad_fn=<TanhBackward0>), tensor([[-0.3919,  0.9491, -0.5649, -0.3300],\n",
      "        [ 0.4541,  0.7331, -0.9386, -0.3017],\n",
      "        [ 0.2587,  0.5719,  0.0430, -0.3093],\n",
      "        [ 0.8444, -0.4690, -0.7024, -0.4686]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1439, -0.7789, -0.4989,  0.1621],\n",
      "        [ 0.7003, -0.2002,  0.1339, -0.2751],\n",
      "        [ 0.0476, -0.2922, -0.1228,  0.8429],\n",
      "        [ 0.6473,  0.4921,  0.5074,  0.6556]], grad_fn=<TanhBackward0>), tensor([[-0.3934,  0.9495, -0.5662, -0.3324],\n",
      "        [ 0.4563,  0.7344, -0.9388, -0.3008],\n",
      "        [ 0.2597,  0.5727,  0.0444, -0.3117],\n",
      "        [ 0.8465, -0.4711, -0.7016, -0.4679]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1426, -0.7794, -0.5000,  0.1612],\n",
      "        [ 0.7001, -0.2006,  0.1331, -0.2756],\n",
      "        [ 0.0466, -0.2925, -0.1236,  0.8429],\n",
      "        [ 0.6473,  0.4924,  0.5073,  0.6560]], grad_fn=<TanhBackward0>), tensor([[-0.3949,  0.9500, -0.5674, -0.3347],\n",
      "        [ 0.4585,  0.7356, -0.9391, -0.3000],\n",
      "        [ 0.2606,  0.5735,  0.0458, -0.3141],\n",
      "        [ 0.8485, -0.4731, -0.7009, -0.4672]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1414, -0.7799, -0.5012,  0.1602],\n",
      "        [ 0.7000, -0.2011,  0.1323, -0.2761],\n",
      "        [ 0.0457, -0.2929, -0.1244,  0.8430],\n",
      "        [ 0.6473,  0.4927,  0.5072,  0.6564]], grad_fn=<TanhBackward0>), tensor([[-0.3963,  0.9504, -0.5686, -0.3370],\n",
      "        [ 0.4606,  0.7368, -0.9394, -0.2992],\n",
      "        [ 0.2615,  0.5743,  0.0471, -0.3165],\n",
      "        [ 0.8505, -0.4750, -0.7001, -0.4666]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1402, -0.7804, -0.5023,  0.1593],\n",
      "        [ 0.6999, -0.2015,  0.1315, -0.2765],\n",
      "        [ 0.0447, -0.2932, -0.1252,  0.8431],\n",
      "        [ 0.6473,  0.4929,  0.5071,  0.6568]], grad_fn=<TanhBackward0>), tensor([[-0.3976,  0.9509, -0.5698, -0.3391],\n",
      "        [ 0.4627,  0.7380, -0.9396, -0.2983],\n",
      "        [ 0.2623,  0.5750,  0.0484, -0.3187],\n",
      "        [ 0.8524, -0.4769, -0.6994, -0.4659]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1390, -0.7808, -0.5033,  0.1585],\n",
      "        [ 0.6998, -0.2019,  0.1308, -0.2770],\n",
      "        [ 0.0438, -0.2936, -0.1260,  0.8432],\n",
      "        [ 0.6473,  0.4932,  0.5070,  0.6571]], grad_fn=<TanhBackward0>), tensor([[-0.3989,  0.9513, -0.5709, -0.3412],\n",
      "        [ 0.4647,  0.7391, -0.9399, -0.2975],\n",
      "        [ 0.2632,  0.5757,  0.0497, -0.3209],\n",
      "        [ 0.8542, -0.4787, -0.6988, -0.4653]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1379, -0.7813, -0.5043,  0.1577],\n",
      "        [ 0.6996, -0.2023,  0.1301, -0.2774],\n",
      "        [ 0.0429, -0.2939, -0.1267,  0.8432],\n",
      "        [ 0.6474,  0.4935,  0.5069,  0.6575]], grad_fn=<TanhBackward0>), tensor([[-0.4002,  0.9516, -0.5719, -0.3432],\n",
      "        [ 0.4666,  0.7403, -0.9401, -0.2967],\n",
      "        [ 0.2640,  0.5764,  0.0510, -0.3231],\n",
      "        [ 0.8559, -0.4805, -0.6981, -0.4647]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1368, -0.7817, -0.5053,  0.1568],\n",
      "        [ 0.6995, -0.2027,  0.1294, -0.2778],\n",
      "        [ 0.0420, -0.2942, -0.1274,  0.8433],\n",
      "        [ 0.6474,  0.4937,  0.5068,  0.6578]], grad_fn=<TanhBackward0>), tensor([[-0.4015,  0.9520, -0.5730, -0.3451],\n",
      "        [ 0.4685,  0.7413, -0.9403, -0.2959],\n",
      "        [ 0.2648,  0.5771,  0.0522, -0.3252],\n",
      "        [ 0.8576, -0.4822, -0.6975, -0.4642]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1357, -0.7821, -0.5063,  0.1561],\n",
      "        [ 0.6994, -0.2030,  0.1287, -0.2782],\n",
      "        [ 0.0412, -0.2945, -0.1282,  0.8433],\n",
      "        [ 0.6474,  0.4939,  0.5067,  0.6581]], grad_fn=<TanhBackward0>), tensor([[-0.4027,  0.9524, -0.5740, -0.3469],\n",
      "        [ 0.4704,  0.7424, -0.9406, -0.2951],\n",
      "        [ 0.2655,  0.5778,  0.0534, -0.3272],\n",
      "        [ 0.8592, -0.4839, -0.6968, -0.4636]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1347, -0.7825, -0.5072,  0.1553],\n",
      "        [ 0.6993, -0.2034,  0.1280, -0.2786],\n",
      "        [ 0.0403, -0.2949, -0.1289,  0.8434],\n",
      "        [ 0.6474,  0.4942,  0.5066,  0.6584]], grad_fn=<TanhBackward0>), tensor([[-0.4039,  0.9527, -0.5749, -0.3487],\n",
      "        [ 0.4721,  0.7434, -0.9408, -0.2943],\n",
      "        [ 0.2663,  0.5785,  0.0545, -0.3292],\n",
      "        [ 0.8608, -0.4855, -0.6963, -0.4631]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1337, -0.7829, -0.5081,  0.1546],\n",
      "        [ 0.6992, -0.2038,  0.1274, -0.2790],\n",
      "        [ 0.0395, -0.2952, -0.1295,  0.8434],\n",
      "        [ 0.6474,  0.4944,  0.5065,  0.6587]], grad_fn=<TanhBackward0>), tensor([[-0.4050,  0.9531, -0.5759, -0.3504],\n",
      "        [ 0.4739,  0.7443, -0.9410, -0.2935],\n",
      "        [ 0.2670,  0.5791,  0.0557, -0.3311],\n",
      "        [ 0.8623, -0.4871, -0.6957, -0.4626]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1327, -0.7832, -0.5089,  0.1539],\n",
      "        [ 0.6991, -0.2041,  0.1268, -0.2794],\n",
      "        [ 0.0387, -0.2955, -0.1302,  0.8435],\n",
      "        [ 0.6474,  0.4946,  0.5064,  0.6590]], grad_fn=<TanhBackward0>), tensor([[-0.4061,  0.9534, -0.5767, -0.3520],\n",
      "        [ 0.4756,  0.7453, -0.9412, -0.2927],\n",
      "        [ 0.2677,  0.5798,  0.0568, -0.3330],\n",
      "        [ 0.8638, -0.4886, -0.6951, -0.4621]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1317, -0.7836, -0.5098,  0.1532],\n",
      "        [ 0.6990, -0.2044,  0.1262, -0.2797],\n",
      "        [ 0.0379, -0.2958, -0.1308,  0.8435],\n",
      "        [ 0.6473,  0.4948,  0.5063,  0.6593]], grad_fn=<TanhBackward0>), tensor([[-0.4072,  0.9537, -0.5776, -0.3536],\n",
      "        [ 0.4772,  0.7462, -0.9414, -0.2919],\n",
      "        [ 0.2684,  0.5804,  0.0578, -0.3348],\n",
      "        [ 0.8652, -0.4900, -0.6946, -0.4616]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1308, -0.7839, -0.5106,  0.1525],\n",
      "        [ 0.6989, -0.2047,  0.1256, -0.2800],\n",
      "        [ 0.0372, -0.2961, -0.1315,  0.8436],\n",
      "        [ 0.6473,  0.4950,  0.5062,  0.6596]], grad_fn=<TanhBackward0>), tensor([[-0.4082,  0.9540, -0.5784, -0.3552],\n",
      "        [ 0.4788,  0.7471, -0.9416, -0.2911],\n",
      "        [ 0.2691,  0.5810,  0.0589, -0.3366],\n",
      "        [ 0.8665, -0.4914, -0.6941, -0.4612]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1299, -0.7843, -0.5114,  0.1519],\n",
      "        [ 0.6988, -0.2050,  0.1251, -0.2803],\n",
      "        [ 0.0364, -0.2964, -0.1321,  0.8436],\n",
      "        [ 0.6473,  0.4951,  0.5061,  0.6598]], grad_fn=<TanhBackward0>), tensor([[-0.4093,  0.9543, -0.5792, -0.3566],\n",
      "        [ 0.4804,  0.7479, -0.9418, -0.2904],\n",
      "        [ 0.2697,  0.5816,  0.0599, -0.3383],\n",
      "        [ 0.8678, -0.4928, -0.6936, -0.4607]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1291, -0.7846, -0.5121,  0.1513],\n",
      "        [ 0.6987, -0.2053,  0.1246, -0.2806],\n",
      "        [ 0.0357, -0.2967, -0.1327,  0.8437],\n",
      "        [ 0.6473,  0.4953,  0.5060,  0.6601]], grad_fn=<TanhBackward0>), tensor([[-0.4103,  0.9546, -0.5800, -0.3580],\n",
      "        [ 0.4819,  0.7487, -0.9419, -0.2896],\n",
      "        [ 0.2703,  0.5822,  0.0609, -0.3399],\n",
      "        [ 0.8691, -0.4941, -0.6931, -0.4603]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1282, -0.7849, -0.5129,  0.1507],\n",
      "        [ 0.6986, -0.2056,  0.1240, -0.2809],\n",
      "        [ 0.0350, -0.2969, -0.1333,  0.8437],\n",
      "        [ 0.6473,  0.4955,  0.5059,  0.6603]], grad_fn=<TanhBackward0>), tensor([[-0.4112,  0.9549, -0.5807, -0.3594],\n",
      "        [ 0.4833,  0.7495, -0.9421, -0.2889],\n",
      "        [ 0.2709,  0.5827,  0.0619, -0.3416],\n",
      "        [ 0.8703, -0.4954, -0.6926, -0.4599]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1274, -0.7852, -0.5136,  0.1501],\n",
      "        [ 0.6985, -0.2059,  0.1235, -0.2812],\n",
      "        [ 0.0343, -0.2972, -0.1338,  0.8438],\n",
      "        [ 0.6473,  0.4956,  0.5058,  0.6606]], grad_fn=<TanhBackward0>), tensor([[-0.4121,  0.9551, -0.5815, -0.3607],\n",
      "        [ 0.4847,  0.7503, -0.9423, -0.2881],\n",
      "        [ 0.2715,  0.5833,  0.0628, -0.3431],\n",
      "        [ 0.8714, -0.4967, -0.6921, -0.4595]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1266, -0.7855, -0.5143,  0.1495],\n",
      "        [ 0.6984, -0.2061,  0.1230, -0.2815],\n",
      "        [ 0.0336, -0.2975, -0.1344,  0.8438],\n",
      "        [ 0.6473,  0.4958,  0.5058,  0.6608]], grad_fn=<TanhBackward0>), tensor([[-0.4130,  0.9554, -0.5822, -0.3620],\n",
      "        [ 0.4861,  0.7511, -0.9424, -0.2874],\n",
      "        [ 0.2721,  0.5838,  0.0638, -0.3447],\n",
      "        [ 0.8725, -0.4979, -0.6917, -0.4591]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1258, -0.7858, -0.5150,  0.1490],\n",
      "        [ 0.6983, -0.2064,  0.1226, -0.2818],\n",
      "        [ 0.0330, -0.2977, -0.1349,  0.8438],\n",
      "        [ 0.6472,  0.4959,  0.5057,  0.6610]], grad_fn=<TanhBackward0>), tensor([[-0.4139,  0.9556, -0.5828, -0.3632],\n",
      "        [ 0.4875,  0.7518, -0.9426, -0.2867],\n",
      "        [ 0.2726,  0.5844,  0.0647, -0.3462],\n",
      "        [ 0.8736, -0.4990, -0.6913, -0.4588]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1251, -0.7861, -0.5156,  0.1485],\n",
      "        [ 0.6983, -0.2067,  0.1221, -0.2820],\n",
      "        [ 0.0323, -0.2980, -0.1354,  0.8439],\n",
      "        [ 0.6472,  0.4961,  0.5056,  0.6613]], grad_fn=<TanhBackward0>), tensor([[-0.4148,  0.9559, -0.5835, -0.3644],\n",
      "        [ 0.4888,  0.7525, -0.9427, -0.2859],\n",
      "        [ 0.2732,  0.5849,  0.0655, -0.3476],\n",
      "        [ 0.8747, -0.5002, -0.6909, -0.4584]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1244, -0.7863, -0.5162,  0.1480],\n",
      "        [ 0.6982, -0.2069,  0.1217, -0.2823],\n",
      "        [ 0.0317, -0.2983, -0.1360,  0.8439],\n",
      "        [ 0.6472,  0.4962,  0.5055,  0.6615]], grad_fn=<TanhBackward0>), tensor([[-0.4156,  0.9561, -0.5841, -0.3655],\n",
      "        [ 0.4900,  0.7532, -0.9429, -0.2852],\n",
      "        [ 0.2737,  0.5854,  0.0664, -0.3490],\n",
      "        [ 0.8757, -0.5013, -0.6905, -0.4581]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1237, -0.7866, -0.5168,  0.1475],\n",
      "        [ 0.6981, -0.2071,  0.1213, -0.2825],\n",
      "        [ 0.0311, -0.2985, -0.1365,  0.8440],\n",
      "        [ 0.6472,  0.4963,  0.5054,  0.6617]], grad_fn=<TanhBackward0>), tensor([[-0.4164,  0.9563, -0.5847, -0.3666],\n",
      "        [ 0.4913,  0.7538, -0.9430, -0.2846],\n",
      "        [ 0.2742,  0.5859,  0.0672, -0.3504],\n",
      "        [ 0.8767, -0.5023, -0.6901, -0.4577]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1230, -0.7868, -0.5174,  0.1470],\n",
      "        [ 0.6980, -0.2074,  0.1209, -0.2827],\n",
      "        [ 0.0305, -0.2987, -0.1369,  0.8440],\n",
      "        [ 0.6472,  0.4964,  0.5054,  0.6619]], grad_fn=<TanhBackward0>), tensor([[-0.4172,  0.9565, -0.5853, -0.3677],\n",
      "        [ 0.4925,  0.7545, -0.9432, -0.2839],\n",
      "        [ 0.2747,  0.5864,  0.0680, -0.3517],\n",
      "        [ 0.8776, -0.5034, -0.6897, -0.4574]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1223, -0.7871, -0.5180,  0.1465],\n",
      "        [ 0.6980, -0.2076,  0.1205, -0.2829],\n",
      "        [ 0.0300, -0.2990, -0.1374,  0.8440],\n",
      "        [ 0.6471,  0.4965,  0.5053,  0.6621]], grad_fn=<TanhBackward0>), tensor([[-0.4179,  0.9567, -0.5858, -0.3687],\n",
      "        [ 0.4936,  0.7551, -0.9433, -0.2832],\n",
      "        [ 0.2752,  0.5868,  0.0688, -0.3530],\n",
      "        [ 0.8785, -0.5043, -0.6893, -0.4571]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1217, -0.7873, -0.5186,  0.1461],\n",
      "        [ 0.6979, -0.2078,  0.1201, -0.2832],\n",
      "        [ 0.0294, -0.2992, -0.1379,  0.8440],\n",
      "        [ 0.6471,  0.4967,  0.5052,  0.6623]], grad_fn=<TanhBackward0>), tensor([[-0.4186,  0.9569, -0.5864, -0.3697],\n",
      "        [ 0.4947,  0.7557, -0.9434, -0.2825],\n",
      "        [ 0.2756,  0.5873,  0.0696, -0.3542],\n",
      "        [ 0.8794, -0.5053, -0.6890, -0.4568]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1210, -0.7876, -0.5191,  0.1457],\n",
      "        [ 0.6978, -0.2080,  0.1197, -0.2834],\n",
      "        [ 0.0289, -0.2994, -0.1383,  0.8441],\n",
      "        [ 0.6471,  0.4968,  0.5051,  0.6624]], grad_fn=<TanhBackward0>), tensor([[-0.4193,  0.9571, -0.5869, -0.3706],\n",
      "        [ 0.4958,  0.7563, -0.9435, -0.2819],\n",
      "        [ 0.2761,  0.5877,  0.0703, -0.3555],\n",
      "        [ 0.8802, -0.5062, -0.6886, -0.4565]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1204, -0.7878, -0.5196,  0.1452],\n",
      "        [ 0.6978, -0.2082,  0.1193, -0.2836],\n",
      "        [ 0.0283, -0.2997, -0.1387,  0.8441],\n",
      "        [ 0.6471,  0.4969,  0.5051,  0.6626]], grad_fn=<TanhBackward0>), tensor([[-0.4200,  0.9573, -0.5874, -0.3716],\n",
      "        [ 0.4969,  0.7568, -0.9437, -0.2813],\n",
      "        [ 0.2765,  0.5882,  0.0711, -0.3566],\n",
      "        [ 0.8810, -0.5071, -0.6883, -0.4562]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1199, -0.7880, -0.5201,  0.1448],\n",
      "        [ 0.6977, -0.2084,  0.1190, -0.2838],\n",
      "        [ 0.0278, -0.2999, -0.1392,  0.8441],\n",
      "        [ 0.6470,  0.4970,  0.5050,  0.6628]], grad_fn=<TanhBackward0>), tensor([[-0.4207,  0.9575, -0.5879, -0.3724],\n",
      "        [ 0.4979,  0.7574, -0.9438, -0.2806],\n",
      "        [ 0.2769,  0.5886,  0.0718, -0.3578],\n",
      "        [ 0.8818, -0.5080, -0.6880, -0.4559]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1193, -0.7882, -0.5206,  0.1444],\n",
      "        [ 0.6976, -0.2086,  0.1186, -0.2839],\n",
      "        [ 0.0273, -0.3001, -0.1396,  0.8442],\n",
      "        [ 0.6470,  0.4971,  0.5049,  0.6629]], grad_fn=<TanhBackward0>), tensor([[-0.4213,  0.9577, -0.5883, -0.3733],\n",
      "        [ 0.4989,  0.7579, -0.9439, -0.2800],\n",
      "        [ 0.2774,  0.5890,  0.0725, -0.3589],\n",
      "        [ 0.8826, -0.5089, -0.6877, -0.4557]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1187, -0.7884, -0.5211,  0.1441],\n",
      "        [ 0.6976, -0.2087,  0.1183, -0.2841],\n",
      "        [ 0.0268, -0.3003, -0.1400,  0.8442],\n",
      "        [ 0.6470,  0.4972,  0.5049,  0.6631]], grad_fn=<TanhBackward0>), tensor([[-0.4220,  0.9579, -0.5888, -0.3741],\n",
      "        [ 0.4999,  0.7584, -0.9440, -0.2794],\n",
      "        [ 0.2778,  0.5894,  0.0731, -0.3600],\n",
      "        [ 0.8833, -0.5097, -0.6874, -0.4554]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1182, -0.7886, -0.5215,  0.1437],\n",
      "        [ 0.6975, -0.2089,  0.1180, -0.2843],\n",
      "        [ 0.0263, -0.3005, -0.1404,  0.8442],\n",
      "        [ 0.6470,  0.4972,  0.5048,  0.6633]], grad_fn=<TanhBackward0>), tensor([[-0.4226,  0.9580, -0.5892, -0.3749],\n",
      "        [ 0.5009,  0.7589, -0.9441, -0.2788],\n",
      "        [ 0.2781,  0.5898,  0.0738, -0.3610],\n",
      "        [ 0.8840, -0.5105, -0.6871, -0.4552]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1177, -0.7888, -0.5220,  0.1433],\n",
      "        [ 0.6975, -0.2091,  0.1177, -0.2844],\n",
      "        [ 0.0259, -0.3007, -0.1407,  0.8442],\n",
      "        [ 0.6469,  0.4973,  0.5047,  0.6634]], grad_fn=<TanhBackward0>), tensor([[-0.4232,  0.9582, -0.5896, -0.3757],\n",
      "        [ 0.5018,  0.7594, -0.9442, -0.2782],\n",
      "        [ 0.2785,  0.5902,  0.0744, -0.3621],\n",
      "        [ 0.8847, -0.5113, -0.6868, -0.4549]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1172, -0.7890, -0.5224,  0.1430],\n",
      "        [ 0.6974, -0.2092,  0.1174, -0.2846],\n",
      "        [ 0.0254, -0.3009, -0.1411,  0.8442],\n",
      "        [ 0.6469,  0.4974,  0.5047,  0.6635]], grad_fn=<TanhBackward0>), tensor([[-0.4237,  0.9583, -0.5900, -0.3764],\n",
      "        [ 0.5027,  0.7599, -0.9443, -0.2777],\n",
      "        [ 0.2789,  0.5906,  0.0751, -0.3630],\n",
      "        [ 0.8854, -0.5120, -0.6865, -0.4547]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1167, -0.7892, -0.5228,  0.1426],\n",
      "        [ 0.6974, -0.2094,  0.1171, -0.2848],\n",
      "        [ 0.0250, -0.3011, -0.1415,  0.8443],\n",
      "        [ 0.6469,  0.4975,  0.5046,  0.6637]], grad_fn=<TanhBackward0>), tensor([[-0.4243,  0.9585, -0.5904, -0.3771],\n",
      "        [ 0.5036,  0.7603, -0.9444, -0.2771],\n",
      "        [ 0.2792,  0.5909,  0.0757, -0.3640],\n",
      "        [ 0.8860, -0.5127, -0.6863, -0.4545]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1162, -0.7893, -0.5232,  0.1423],\n",
      "        [ 0.6973, -0.2095,  0.1168, -0.2849],\n",
      "        [ 0.0246, -0.3013, -0.1418,  0.8443],\n",
      "        [ 0.6469,  0.4976,  0.5045,  0.6638]], grad_fn=<TanhBackward0>), tensor([[-0.4248,  0.9586, -0.5908, -0.3778],\n",
      "        [ 0.5044,  0.7608, -0.9445, -0.2766],\n",
      "        [ 0.2796,  0.5913,  0.0763, -0.3649],\n",
      "        [ 0.8867, -0.5134, -0.6860, -0.4542]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1157, -0.7895, -0.5236,  0.1420],\n",
      "        [ 0.6973, -0.2097,  0.1166, -0.2851],\n",
      "        [ 0.0242, -0.3014, -0.1421,  0.8443],\n",
      "        [ 0.6469,  0.4976,  0.5045,  0.6640]], grad_fn=<TanhBackward0>), tensor([[-0.4253,  0.9588, -0.5912, -0.3785],\n",
      "        [ 0.5052,  0.7612, -0.9446, -0.2760],\n",
      "        [ 0.2799,  0.5916,  0.0768, -0.3659],\n",
      "        [ 0.8873, -0.5141, -0.6858, -0.4540]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1153, -0.7897, -0.5240,  0.1417],\n",
      "        [ 0.6972, -0.2098,  0.1163, -0.2852],\n",
      "        [ 0.0238, -0.3016, -0.1425,  0.8443],\n",
      "        [ 0.6468,  0.4977,  0.5044,  0.6641]], grad_fn=<TanhBackward0>), tensor([[-0.4258,  0.9589, -0.5916, -0.3791],\n",
      "        [ 0.5060,  0.7616, -0.9447, -0.2755],\n",
      "        [ 0.2802,  0.5920,  0.0774, -0.3667],\n",
      "        [ 0.8879, -0.5148, -0.6855, -0.4538]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1149, -0.7898, -0.5244,  0.1414],\n",
      "        [ 0.6972, -0.2100,  0.1160, -0.2853],\n",
      "        [ 0.0234, -0.3018, -0.1428,  0.8443],\n",
      "        [ 0.6468,  0.4978,  0.5044,  0.6642]], grad_fn=<TanhBackward0>), tensor([[-0.4263,  0.9590, -0.5919, -0.3798],\n",
      "        [ 0.5068,  0.7620, -0.9448, -0.2750],\n",
      "        [ 0.2806,  0.5923,  0.0779, -0.3676],\n",
      "        [ 0.8884, -0.5154, -0.6853, -0.4536]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1144, -0.7900, -0.5247,  0.1411],\n",
      "        [ 0.6971, -0.2101,  0.1158, -0.2855],\n",
      "        [ 0.0230, -0.3019, -0.1431,  0.8444],\n",
      "        [ 0.6468,  0.4978,  0.5043,  0.6643]], grad_fn=<TanhBackward0>), tensor([[-0.4268,  0.9592, -0.5922, -0.3804],\n",
      "        [ 0.5075,  0.7624, -0.9448, -0.2745],\n",
      "        [ 0.2809,  0.5926,  0.0785, -0.3684],\n",
      "        [ 0.8890, -0.5160, -0.6851, -0.4534]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1140, -0.7901, -0.5251,  0.1408],\n",
      "        [ 0.6971, -0.2102,  0.1156, -0.2856],\n",
      "        [ 0.0226, -0.3021, -0.1434,  0.8444],\n",
      "        [ 0.6468,  0.4979,  0.5043,  0.6644]], grad_fn=<TanhBackward0>), tensor([[-0.4273,  0.9593, -0.5926, -0.3809],\n",
      "        [ 0.5083,  0.7628, -0.9449, -0.2740],\n",
      "        [ 0.2812,  0.5929,  0.0790, -0.3692],\n",
      "        [ 0.8895, -0.5166, -0.6848, -0.4532]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1136, -0.7903, -0.5254,  0.1406],\n",
      "        [ 0.6970, -0.2104,  0.1153, -0.2857],\n",
      "        [ 0.0222, -0.3023, -0.1437,  0.8444],\n",
      "        [ 0.6467,  0.4980,  0.5042,  0.6646]], grad_fn=<TanhBackward0>), tensor([[-0.4277,  0.9594, -0.5929, -0.3815],\n",
      "        [ 0.5090,  0.7631, -0.9450, -0.2735],\n",
      "        [ 0.2814,  0.5932,  0.0795, -0.3700],\n",
      "        [ 0.8900, -0.5172, -0.6846, -0.4530]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1132, -0.7904, -0.5257,  0.1403],\n",
      "        [ 0.6970, -0.2105,  0.1151, -0.2858],\n",
      "        [ 0.0219, -0.3024, -0.1440,  0.8444],\n",
      "        [ 0.6467,  0.4980,  0.5042,  0.6647]], grad_fn=<TanhBackward0>), tensor([[-0.4282,  0.9595, -0.5932, -0.3820],\n",
      "        [ 0.5097,  0.7635, -0.9451, -0.2730],\n",
      "        [ 0.2817,  0.5935,  0.0800, -0.3708],\n",
      "        [ 0.8905, -0.5178, -0.6844, -0.4529]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1129, -0.7905, -0.5261,  0.1400],\n",
      "        [ 0.6970, -0.2106,  0.1149, -0.2859],\n",
      "        [ 0.0216, -0.3026, -0.1443,  0.8444],\n",
      "        [ 0.6467,  0.4981,  0.5041,  0.6648]], grad_fn=<TanhBackward0>), tensor([[-0.4286,  0.9596, -0.5935, -0.3826],\n",
      "        [ 0.5104,  0.7638, -0.9451, -0.2725],\n",
      "        [ 0.2820,  0.5938,  0.0804, -0.3715],\n",
      "        [ 0.8910, -0.5183, -0.6842, -0.4527]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1125, -0.7907, -0.5264,  0.1398],\n",
      "        [ 0.6969, -0.2107,  0.1147, -0.2860],\n",
      "        [ 0.0212, -0.3027, -0.1445,  0.8444],\n",
      "        [ 0.6467,  0.4981,  0.5041,  0.6649]], grad_fn=<TanhBackward0>), tensor([[-0.4290,  0.9597, -0.5937, -0.3831],\n",
      "        [ 0.5110,  0.7642, -0.9452, -0.2721],\n",
      "        [ 0.2823,  0.5941,  0.0809, -0.3723],\n",
      "        [ 0.8914, -0.5189, -0.6840, -0.4525]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1121, -0.7908, -0.5267,  0.1396],\n",
      "        [ 0.6969, -0.2108,  0.1145, -0.2861],\n",
      "        [ 0.0209, -0.3028, -0.1448,  0.8445],\n",
      "        [ 0.6466,  0.4982,  0.5040,  0.6650]], grad_fn=<TanhBackward0>), tensor([[-0.4294,  0.9598, -0.5940, -0.3836],\n",
      "        [ 0.5116,  0.7645, -0.9453, -0.2716],\n",
      "        [ 0.2825,  0.5943,  0.0813, -0.3730],\n",
      "        [ 0.8919, -0.5194, -0.6838, -0.4524]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1118, -0.7909, -0.5269,  0.1393],\n",
      "        [ 0.6969, -0.2109,  0.1143, -0.2862],\n",
      "        [ 0.0206, -0.3030, -0.1451,  0.8445],\n",
      "        [ 0.6466,  0.4982,  0.5040,  0.6651]], grad_fn=<TanhBackward0>), tensor([[-0.4298,  0.9599, -0.5943, -0.3840],\n",
      "        [ 0.5123,  0.7648, -0.9453, -0.2712],\n",
      "        [ 0.2828,  0.5946,  0.0818, -0.3736],\n",
      "        [ 0.8923, -0.5199, -0.6837, -0.4522]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1115, -0.7910, -0.5272,  0.1391],\n",
      "        [ 0.6968, -0.2110,  0.1141, -0.2863],\n",
      "        [ 0.0203, -0.3031, -0.1453,  0.8445],\n",
      "        [ 0.6466,  0.4983,  0.5039,  0.6652]], grad_fn=<TanhBackward0>), tensor([[-0.4302,  0.9600, -0.5945, -0.3845],\n",
      "        [ 0.5129,  0.7651, -0.9454, -0.2708],\n",
      "        [ 0.2830,  0.5949,  0.0822, -0.3743],\n",
      "        [ 0.8927, -0.5204, -0.6835, -0.4520]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1111, -0.7912, -0.5275,  0.1389],\n",
      "        [ 0.6968, -0.2111,  0.1139, -0.2864],\n",
      "        [ 0.0200, -0.3032, -0.1455,  0.8445],\n",
      "        [ 0.6466,  0.4983,  0.5039,  0.6653]], grad_fn=<TanhBackward0>), tensor([[-0.4305,  0.9601, -0.5948, -0.3850],\n",
      "        [ 0.5134,  0.7654, -0.9455, -0.2704],\n",
      "        [ 0.2832,  0.5951,  0.0826, -0.3749],\n",
      "        [ 0.8931, -0.5208, -0.6833, -0.4519]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1108, -0.7913, -0.5278,  0.1387],\n",
      "        [ 0.6968, -0.2112,  0.1137, -0.2865],\n",
      "        [ 0.0197, -0.3034, -0.1458,  0.8445],\n",
      "        [ 0.6466,  0.4984,  0.5038,  0.6653]], grad_fn=<TanhBackward0>), tensor([[-0.4309,  0.9602, -0.5950, -0.3854],\n",
      "        [ 0.5140,  0.7657, -0.9455, -0.2700],\n",
      "        [ 0.2835,  0.5954,  0.0830, -0.3756],\n",
      "        [ 0.8935, -0.5213, -0.6831, -0.4517]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1105, -0.7914, -0.5280,  0.1385],\n",
      "        [ 0.6967, -0.2113,  0.1136, -0.2866],\n",
      "        [ 0.0194, -0.3035, -0.1460,  0.8445],\n",
      "        [ 0.6465,  0.4984,  0.5038,  0.6654]], grad_fn=<TanhBackward0>), tensor([[-0.4312,  0.9603, -0.5953, -0.3858],\n",
      "        [ 0.5146,  0.7660, -0.9456, -0.2696],\n",
      "        [ 0.2837,  0.5956,  0.0834, -0.3762],\n",
      "        [ 0.8939, -0.5217, -0.6830, -0.4516]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1102, -0.7915, -0.5283,  0.1383],\n",
      "        [ 0.6967, -0.2114,  0.1134, -0.2867],\n",
      "        [ 0.0191, -0.3036, -0.1462,  0.8445],\n",
      "        [ 0.6465,  0.4985,  0.5038,  0.6655]], grad_fn=<TanhBackward0>), tensor([[-0.4316,  0.9604, -0.5955, -0.3862],\n",
      "        [ 0.5151,  0.7662, -0.9456, -0.2692],\n",
      "        [ 0.2839,  0.5958,  0.0838, -0.3768],\n",
      "        [ 0.8943, -0.5222, -0.6828, -0.4515]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1099, -0.7916, -0.5285,  0.1381],\n",
      "        [ 0.6967, -0.2115,  0.1132, -0.2868],\n",
      "        [ 0.0189, -0.3037, -0.1464,  0.8445],\n",
      "        [ 0.6465,  0.4985,  0.5037,  0.6656]], grad_fn=<TanhBackward0>), tensor([[-0.4319,  0.9605, -0.5957, -0.3866],\n",
      "        [ 0.5156,  0.7665, -0.9457, -0.2688],\n",
      "        [ 0.2841,  0.5961,  0.0842, -0.3773],\n",
      "        [ 0.8947, -0.5226, -0.6827, -0.4513]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1096, -0.7917, -0.5287,  0.1379],\n",
      "        [ 0.6966, -0.2116,  0.1131, -0.2869],\n",
      "        [ 0.0186, -0.3038, -0.1467,  0.8446],\n",
      "        [ 0.6465,  0.4985,  0.5037,  0.6657]], grad_fn=<TanhBackward0>), tensor([[-0.4322,  0.9606, -0.5959, -0.3870],\n",
      "        [ 0.5161,  0.7668, -0.9457, -0.2684],\n",
      "        [ 0.2843,  0.5963,  0.0845, -0.3779],\n",
      "        [ 0.8950, -0.5230, -0.6825, -0.4512]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1094, -0.7918, -0.5290,  0.1377],\n",
      "        [ 0.6966, -0.2117,  0.1129, -0.2869],\n",
      "        [ 0.0183, -0.3040, -0.1469,  0.8446],\n",
      "        [ 0.6465,  0.4986,  0.5036,  0.6658]], grad_fn=<TanhBackward0>), tensor([[-0.4325,  0.9607, -0.5961, -0.3873],\n",
      "        [ 0.5166,  0.7670, -0.9458, -0.2680],\n",
      "        [ 0.2845,  0.5965,  0.0849, -0.3784],\n",
      "        [ 0.8953, -0.5234, -0.6824, -0.4511]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1091, -0.7919, -0.5292,  0.1375],\n",
      "        [ 0.6966, -0.2118,  0.1128, -0.2870],\n",
      "        [ 0.0181, -0.3041, -0.1471,  0.8446],\n",
      "        [ 0.6464,  0.4986,  0.5036,  0.6658]], grad_fn=<TanhBackward0>), tensor([[-0.4328,  0.9607, -0.5963, -0.3877],\n",
      "        [ 0.5171,  0.7672, -0.9458, -0.2677],\n",
      "        [ 0.2847,  0.5967,  0.0852, -0.3790],\n",
      "        [ 0.8957, -0.5238, -0.6822, -0.4509]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1089, -0.7920, -0.5294,  0.1374],\n",
      "        [ 0.6965, -0.2118,  0.1126, -0.2871],\n",
      "        [ 0.0179, -0.3042, -0.1473,  0.8446],\n",
      "        [ 0.6464,  0.4987,  0.5036,  0.6659]], grad_fn=<TanhBackward0>), tensor([[-0.4331,  0.9608, -0.5965, -0.3880],\n",
      "        [ 0.5176,  0.7675, -0.9459, -0.2673],\n",
      "        [ 0.2849,  0.5969,  0.0855, -0.3795],\n",
      "        [ 0.8960, -0.5241, -0.6821, -0.4508]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1086, -0.7921, -0.5296,  0.1372],\n",
      "        [ 0.6965, -0.2119,  0.1125, -0.2872],\n",
      "        [ 0.0176, -0.3043, -0.1474,  0.8446],\n",
      "        [ 0.6464,  0.4987,  0.5035,  0.6660]], grad_fn=<TanhBackward0>), tensor([[-0.4334,  0.9609, -0.5967, -0.3884],\n",
      "        [ 0.5180,  0.7677, -0.9459, -0.2670],\n",
      "        [ 0.2851,  0.5971,  0.0859, -0.3800],\n",
      "        [ 0.8963, -0.5245, -0.6820, -0.4507]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1084, -0.7922, -0.5298,  0.1370],\n",
      "        [ 0.6965, -0.2120,  0.1123, -0.2872],\n",
      "        [ 0.0174, -0.3044, -0.1476,  0.8446],\n",
      "        [ 0.6464,  0.4987,  0.5035,  0.6660]], grad_fn=<TanhBackward0>), tensor([[-0.4336,  0.9610, -0.5969, -0.3887],\n",
      "        [ 0.5184,  0.7679, -0.9460, -0.2667],\n",
      "        [ 0.2852,  0.5973,  0.0862, -0.3804],\n",
      "        [ 0.8966, -0.5248, -0.6818, -0.4506]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [200/1000], Loss: 0.0016569329891353846\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1081, -0.7922, -0.5300,  0.1369],\n",
      "        [ 0.6965, -0.2121,  0.1122, -0.2873],\n",
      "        [ 0.0172, -0.3045, -0.1478,  0.8446],\n",
      "        [ 0.6464,  0.4988,  0.5035,  0.6661]], grad_fn=<TanhBackward0>), tensor([[-0.4339,  0.9610, -0.5971, -0.3890],\n",
      "        [ 0.5189,  0.7681, -0.9460, -0.2663],\n",
      "        [ 0.2854,  0.5975,  0.0865, -0.3809],\n",
      "        [ 0.8969, -0.5252, -0.6817, -0.4505]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1079, -0.7923, -0.5302,  0.1367],\n",
      "        [ 0.6964, -0.2121,  0.1121, -0.2874],\n",
      "        [ 0.0170, -0.3046, -0.1480,  0.8446],\n",
      "        [ 0.6464,  0.4988,  0.5034,  0.6662]], grad_fn=<TanhBackward0>), tensor([[-0.4342,  0.9611, -0.5972, -0.3893],\n",
      "        [ 0.5193,  0.7683, -0.9461, -0.2660],\n",
      "        [ 0.2856,  0.5977,  0.0868, -0.3814],\n",
      "        [ 0.8972, -0.5255, -0.6816, -0.4504]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1077, -0.7924, -0.5304,  0.1366],\n",
      "        [ 0.6964, -0.2122,  0.1120, -0.2874],\n",
      "        [ 0.0168, -0.3047, -0.1481,  0.8446],\n",
      "        [ 0.6463,  0.4988,  0.5034,  0.6662]], grad_fn=<TanhBackward0>), tensor([[-0.4344,  0.9612, -0.5974, -0.3896],\n",
      "        [ 0.5197,  0.7685, -0.9461, -0.2657],\n",
      "        [ 0.2857,  0.5978,  0.0871, -0.3818],\n",
      "        [ 0.8974, -0.5258, -0.6815, -0.4503]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1075, -0.7925, -0.5306,  0.1364],\n",
      "        [ 0.6964, -0.2123,  0.1118, -0.2875],\n",
      "        [ 0.0166, -0.3048, -0.1483,  0.8446],\n",
      "        [ 0.6463,  0.4988,  0.5034,  0.6663]], grad_fn=<TanhBackward0>), tensor([[-0.4346,  0.9612, -0.5976, -0.3899],\n",
      "        [ 0.5201,  0.7687, -0.9462, -0.2654],\n",
      "        [ 0.2859,  0.5980,  0.0873, -0.3822],\n",
      "        [ 0.8977, -0.5261, -0.6814, -0.4502]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1072, -0.7926, -0.5307,  0.1363],\n",
      "        [ 0.6964, -0.2123,  0.1117, -0.2876],\n",
      "        [ 0.0164, -0.3048, -0.1485,  0.8447],\n",
      "        [ 0.6463,  0.4989,  0.5034,  0.6664]], grad_fn=<TanhBackward0>), tensor([[-0.4349,  0.9613, -0.5977, -0.3902],\n",
      "        [ 0.5205,  0.7689, -0.9462, -0.2651],\n",
      "        [ 0.2860,  0.5982,  0.0876, -0.3827],\n",
      "        [ 0.8979, -0.5264, -0.6813, -0.4501]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1070, -0.7926, -0.5309,  0.1362],\n",
      "        [ 0.6964, -0.2124,  0.1116, -0.2876],\n",
      "        [ 0.0162, -0.3049, -0.1486,  0.8447],\n",
      "        [ 0.6463,  0.4989,  0.5033,  0.6664]], grad_fn=<TanhBackward0>), tensor([[-0.4351,  0.9613, -0.5979, -0.3904],\n",
      "        [ 0.5208,  0.7691, -0.9462, -0.2648],\n",
      "        [ 0.2862,  0.5983,  0.0879, -0.3831],\n",
      "        [ 0.8982, -0.5267, -0.6812, -0.4500]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1068, -0.7927, -0.5311,  0.1360],\n",
      "        [ 0.6963, -0.2124,  0.1115, -0.2877],\n",
      "        [ 0.0160, -0.3050, -0.1488,  0.8447],\n",
      "        [ 0.6463,  0.4989,  0.5033,  0.6665]], grad_fn=<TanhBackward0>), tensor([[-0.4353,  0.9614, -0.5980, -0.3907],\n",
      "        [ 0.5212,  0.7693, -0.9463, -0.2645],\n",
      "        [ 0.2863,  0.5985,  0.0881, -0.3835],\n",
      "        [ 0.8984, -0.5270, -0.6811, -0.4499]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1066, -0.7928, -0.5312,  0.1359],\n",
      "        [ 0.6963, -0.2125,  0.1114, -0.2877],\n",
      "        [ 0.0158, -0.3051, -0.1489,  0.8447],\n",
      "        [ 0.6463,  0.4990,  0.5033,  0.6665]], grad_fn=<TanhBackward0>), tensor([[-0.4355,  0.9615, -0.5982, -0.3909],\n",
      "        [ 0.5215,  0.7695, -0.9463, -0.2643],\n",
      "        [ 0.2865,  0.5986,  0.0884, -0.3839],\n",
      "        [ 0.8987, -0.5273, -0.6810, -0.4498]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1065, -0.7928, -0.5314,  0.1358],\n",
      "        [ 0.6963, -0.2126,  0.1113, -0.2878],\n",
      "        [ 0.0156, -0.3052, -0.1491,  0.8447],\n",
      "        [ 0.6463,  0.4990,  0.5032,  0.6666]], grad_fn=<TanhBackward0>), tensor([[-0.4358,  0.9615, -0.5983, -0.3912],\n",
      "        [ 0.5219,  0.7696, -0.9463, -0.2640],\n",
      "        [ 0.2866,  0.5988,  0.0886, -0.3842],\n",
      "        [ 0.8989, -0.5276, -0.6809, -0.4497]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1063, -0.7929, -0.5315,  0.1357],\n",
      "        [ 0.6963, -0.2126,  0.1112, -0.2878],\n",
      "        [ 0.0154, -0.3052, -0.1492,  0.8447],\n",
      "        [ 0.6462,  0.4990,  0.5032,  0.6666]], grad_fn=<TanhBackward0>), tensor([[-0.4360,  0.9616, -0.5984, -0.3914],\n",
      "        [ 0.5222,  0.7698, -0.9464, -0.2637],\n",
      "        [ 0.2867,  0.5989,  0.0889, -0.3846],\n",
      "        [ 0.8991, -0.5278, -0.6808, -0.4496]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1061, -0.7930, -0.5317,  0.1355],\n",
      "        [ 0.6963, -0.2127,  0.1111, -0.2879],\n",
      "        [ 0.0153, -0.3053, -0.1493,  0.8447],\n",
      "        [ 0.6462,  0.4990,  0.5032,  0.6667]], grad_fn=<TanhBackward0>), tensor([[-0.4362,  0.9616, -0.5986, -0.3916],\n",
      "        [ 0.5225,  0.7700, -0.9464, -0.2635],\n",
      "        [ 0.2869,  0.5991,  0.0891, -0.3849],\n",
      "        [ 0.8993, -0.5281, -0.6807, -0.4495]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1059, -0.7930, -0.5318,  0.1354],\n",
      "        [ 0.6962, -0.2127,  0.1110, -0.2879],\n",
      "        [ 0.0151, -0.3054, -0.1495,  0.8447],\n",
      "        [ 0.6462,  0.4991,  0.5032,  0.6667]], grad_fn=<TanhBackward0>), tensor([[-0.4363,  0.9617, -0.5987, -0.3919],\n",
      "        [ 0.5229,  0.7701, -0.9464, -0.2632],\n",
      "        [ 0.2870,  0.5992,  0.0893, -0.3853],\n",
      "        [ 0.8995, -0.5283, -0.6806, -0.4495]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1058, -0.7931, -0.5320,  0.1353],\n",
      "        [ 0.6962, -0.2128,  0.1109, -0.2880],\n",
      "        [ 0.0150, -0.3055, -0.1496,  0.8447],\n",
      "        [ 0.6462,  0.4991,  0.5032,  0.6668]], grad_fn=<TanhBackward0>), tensor([[-0.4365,  0.9617, -0.5988, -0.3921],\n",
      "        [ 0.5232,  0.7703, -0.9465, -0.2630],\n",
      "        [ 0.2871,  0.5993,  0.0895, -0.3856],\n",
      "        [ 0.8997, -0.5286, -0.6805, -0.4494]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1056, -0.7931, -0.5321,  0.1352],\n",
      "        [ 0.6962, -0.2128,  0.1108, -0.2880],\n",
      "        [ 0.0148, -0.3055, -0.1497,  0.8447],\n",
      "        [ 0.6462,  0.4991,  0.5031,  0.6668]], grad_fn=<TanhBackward0>), tensor([[-0.4367,  0.9618, -0.5989, -0.3923],\n",
      "        [ 0.5235,  0.7704, -0.9465, -0.2628],\n",
      "        [ 0.2872,  0.5995,  0.0897, -0.3859],\n",
      "        [ 0.8999, -0.5288, -0.6804, -0.4493]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1054, -0.7932, -0.5322,  0.1351],\n",
      "        [ 0.6962, -0.2129,  0.1107, -0.2881],\n",
      "        [ 0.0147, -0.3056, -0.1498,  0.8447],\n",
      "        [ 0.6462,  0.4991,  0.5031,  0.6669]], grad_fn=<TanhBackward0>), tensor([[-0.4369,  0.9618, -0.5990, -0.3925],\n",
      "        [ 0.5237,  0.7706, -0.9465, -0.2625],\n",
      "        [ 0.2873,  0.5996,  0.0899, -0.3863],\n",
      "        [ 0.9001, -0.5290, -0.6803, -0.4492]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1053, -0.7933, -0.5324,  0.1350],\n",
      "        [ 0.6962, -0.2129,  0.1106, -0.2881],\n",
      "        [ 0.0145, -0.3057, -0.1500,  0.8447],\n",
      "        [ 0.6462,  0.4991,  0.5031,  0.6669]], grad_fn=<TanhBackward0>), tensor([[-0.4371,  0.9618, -0.5991, -0.3927],\n",
      "        [ 0.5240,  0.7707, -0.9466, -0.2623],\n",
      "        [ 0.2875,  0.5997,  0.0902, -0.3866],\n",
      "        [ 0.9003, -0.5292, -0.6803, -0.4492]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1051, -0.7933, -0.5325,  0.1349],\n",
      "        [ 0.6962, -0.2130,  0.1105, -0.2881],\n",
      "        [ 0.0144, -0.3057, -0.1501,  0.8447],\n",
      "        [ 0.6461,  0.4992,  0.5031,  0.6669]], grad_fn=<TanhBackward0>), tensor([[-0.4372,  0.9619, -0.5993, -0.3929],\n",
      "        [ 0.5243,  0.7708, -0.9466, -0.2621],\n",
      "        [ 0.2876,  0.5999,  0.0903, -0.3869],\n",
      "        [ 0.9005, -0.5294, -0.6802, -0.4491]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1050, -0.7934, -0.5326,  0.1348],\n",
      "        [ 0.6961, -0.2130,  0.1105, -0.2882],\n",
      "        [ 0.0142, -0.3058, -0.1502,  0.8447],\n",
      "        [ 0.6461,  0.4992,  0.5030,  0.6670]], grad_fn=<TanhBackward0>), tensor([[-0.4374,  0.9619, -0.5994, -0.3930],\n",
      "        [ 0.5246,  0.7710, -0.9466, -0.2619],\n",
      "        [ 0.2877,  0.6000,  0.0905, -0.3872],\n",
      "        [ 0.9007, -0.5296, -0.6801, -0.4490]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1048, -0.7934, -0.5327,  0.1347],\n",
      "        [ 0.6961, -0.2130,  0.1104, -0.2882],\n",
      "        [ 0.0141, -0.3059, -0.1503,  0.8447],\n",
      "        [ 0.6461,  0.4992,  0.5030,  0.6670]], grad_fn=<TanhBackward0>), tensor([[-0.4375,  0.9620, -0.5995, -0.3932],\n",
      "        [ 0.5248,  0.7711, -0.9466, -0.2617],\n",
      "        [ 0.2878,  0.6001,  0.0907, -0.3874],\n",
      "        [ 0.9008, -0.5298, -0.6800, -0.4490]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1047, -0.7935, -0.5328,  0.1346],\n",
      "        [ 0.6961, -0.2131,  0.1103, -0.2883],\n",
      "        [ 0.0140, -0.3059, -0.1504,  0.8447],\n",
      "        [ 0.6461,  0.4992,  0.5030,  0.6671]], grad_fn=<TanhBackward0>), tensor([[-0.4377,  0.9620, -0.5996, -0.3934],\n",
      "        [ 0.5251,  0.7712, -0.9467, -0.2614],\n",
      "        [ 0.2879,  0.6002,  0.0909, -0.3877],\n",
      "        [ 0.9010, -0.5300, -0.6800, -0.4489]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1046, -0.7935, -0.5329,  0.1345],\n",
      "        [ 0.6961, -0.2131,  0.1102, -0.2883],\n",
      "        [ 0.0138, -0.3060, -0.1505,  0.8448],\n",
      "        [ 0.6461,  0.4992,  0.5030,  0.6671]], grad_fn=<TanhBackward0>), tensor([[-0.4378,  0.9620, -0.5997, -0.3936],\n",
      "        [ 0.5253,  0.7713, -0.9467, -0.2612],\n",
      "        [ 0.2880,  0.6003,  0.0911, -0.3880],\n",
      "        [ 0.9011, -0.5302, -0.6799, -0.4488]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1044, -0.7935, -0.5331,  0.1344],\n",
      "        [ 0.6961, -0.2132,  0.1102, -0.2883],\n",
      "        [ 0.0137, -0.3060, -0.1506,  0.8448],\n",
      "        [ 0.6461,  0.4993,  0.5030,  0.6671]], grad_fn=<TanhBackward0>), tensor([[-0.4380,  0.9621, -0.5998, -0.3937],\n",
      "        [ 0.5256,  0.7715, -0.9467, -0.2611],\n",
      "        [ 0.2881,  0.6004,  0.0912, -0.3882],\n",
      "        [ 0.9013, -0.5304, -0.6798, -0.4488]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1043, -0.7936, -0.5332,  0.1344],\n",
      "        [ 0.6961, -0.2132,  0.1101, -0.2884],\n",
      "        [ 0.0136, -0.3061, -0.1507,  0.8448],\n",
      "        [ 0.6461,  0.4993,  0.5030,  0.6672]], grad_fn=<TanhBackward0>), tensor([[-0.4381,  0.9621, -0.5998, -0.3939],\n",
      "        [ 0.5258,  0.7716, -0.9467, -0.2609],\n",
      "        [ 0.2882,  0.6005,  0.0914, -0.3885],\n",
      "        [ 0.9015, -0.5306, -0.6798, -0.4487]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1042, -0.7936, -0.5333,  0.1343],\n",
      "        [ 0.6961, -0.2132,  0.1100, -0.2884],\n",
      "        [ 0.0135, -0.3061, -0.1508,  0.8448],\n",
      "        [ 0.6461,  0.4993,  0.5029,  0.6672]], grad_fn=<TanhBackward0>), tensor([[-0.4383,  0.9622, -0.5999, -0.3940],\n",
      "        [ 0.5260,  0.7717, -0.9468, -0.2607],\n",
      "        [ 0.2882,  0.6006,  0.0916, -0.3887],\n",
      "        [ 0.9016, -0.5308, -0.6797, -0.4486]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1041, -0.7937, -0.5334,  0.1342],\n",
      "        [ 0.6961, -0.2133,  0.1100, -0.2884],\n",
      "        [ 0.0134, -0.3062, -0.1509,  0.8448],\n",
      "        [ 0.6461,  0.4993,  0.5029,  0.6672]], grad_fn=<TanhBackward0>), tensor([[-0.4384,  0.9622, -0.6000, -0.3942],\n",
      "        [ 0.5262,  0.7718, -0.9468, -0.2605],\n",
      "        [ 0.2883,  0.6007,  0.0917, -0.3890],\n",
      "        [ 0.9017, -0.5309, -0.6796, -0.4486]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1040, -0.7937, -0.5335,  0.1341],\n",
      "        [ 0.6960, -0.2133,  0.1099, -0.2885],\n",
      "        [ 0.0133, -0.3062, -0.1510,  0.8448],\n",
      "        [ 0.6461,  0.4993,  0.5029,  0.6673]], grad_fn=<TanhBackward0>), tensor([[-0.4385,  0.9622, -0.6001, -0.3943],\n",
      "        [ 0.5264,  0.7719, -0.9468, -0.2603],\n",
      "        [ 0.2884,  0.6008,  0.0919, -0.3892],\n",
      "        [ 0.9019, -0.5311, -0.6796, -0.4485]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1038, -0.7938, -0.5335,  0.1341],\n",
      "        [ 0.6960, -0.2133,  0.1098, -0.2885],\n",
      "        [ 0.0131, -0.3063, -0.1510,  0.8448],\n",
      "        [ 0.6460,  0.4993,  0.5029,  0.6673]], grad_fn=<TanhBackward0>), tensor([[-0.4387,  0.9623, -0.6002, -0.3945],\n",
      "        [ 0.5267,  0.7720, -0.9468, -0.2602],\n",
      "        [ 0.2885,  0.6009,  0.0920, -0.3894],\n",
      "        [ 0.9020, -0.5313, -0.6795, -0.4485]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1037, -0.7938, -0.5336,  0.1340],\n",
      "        [ 0.6960, -0.2134,  0.1098, -0.2885],\n",
      "        [ 0.0130, -0.3063, -0.1511,  0.8448],\n",
      "        [ 0.6460,  0.4993,  0.5029,  0.6673]], grad_fn=<TanhBackward0>), tensor([[-0.4388,  0.9623, -0.6003, -0.3946],\n",
      "        [ 0.5269,  0.7721, -0.9468, -0.2600],\n",
      "        [ 0.2886,  0.6010,  0.0922, -0.3897],\n",
      "        [ 0.9021, -0.5314, -0.6795, -0.4484]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1036, -0.7938, -0.5337,  0.1339],\n",
      "        [ 0.6960, -0.2134,  0.1097, -0.2885],\n",
      "        [ 0.0129, -0.3064, -0.1512,  0.8448],\n",
      "        [ 0.6460,  0.4994,  0.5029,  0.6674]], grad_fn=<TanhBackward0>), tensor([[-0.4389,  0.9623, -0.6003, -0.3947],\n",
      "        [ 0.5271,  0.7722, -0.9469, -0.2598],\n",
      "        [ 0.2887,  0.6011,  0.0923, -0.3899],\n",
      "        [ 0.9023, -0.5316, -0.6794, -0.4484]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1035, -0.7939, -0.5338,  0.1338],\n",
      "        [ 0.6960, -0.2134,  0.1097, -0.2886],\n",
      "        [ 0.0128, -0.3064, -0.1513,  0.8448],\n",
      "        [ 0.6460,  0.4994,  0.5028,  0.6674]], grad_fn=<TanhBackward0>), tensor([[-0.4390,  0.9623, -0.6004, -0.3949],\n",
      "        [ 0.5272,  0.7723, -0.9469, -0.2597],\n",
      "        [ 0.2887,  0.6011,  0.0924, -0.3901],\n",
      "        [ 0.9024, -0.5317, -0.6793, -0.4483]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1034, -0.7939, -0.5339,  0.1338],\n",
      "        [ 0.6960, -0.2135,  0.1096, -0.2886],\n",
      "        [ 0.0127, -0.3065, -0.1514,  0.8448],\n",
      "        [ 0.6460,  0.4994,  0.5028,  0.6674]], grad_fn=<TanhBackward0>), tensor([[-0.4391,  0.9624, -0.6005, -0.3950],\n",
      "        [ 0.5274,  0.7724, -0.9469, -0.2595],\n",
      "        [ 0.2888,  0.6012,  0.0926, -0.3903],\n",
      "        [ 0.9025, -0.5319, -0.6793, -0.4483]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1033, -0.7939, -0.5340,  0.1337],\n",
      "        [ 0.6960, -0.2135,  0.1095, -0.2886],\n",
      "        [ 0.0127, -0.3065, -0.1514,  0.8448],\n",
      "        [ 0.6460,  0.4994,  0.5028,  0.6674]], grad_fn=<TanhBackward0>), tensor([[-0.4392,  0.9624, -0.6006, -0.3951],\n",
      "        [ 0.5276,  0.7725, -0.9469, -0.2594],\n",
      "        [ 0.2889,  0.6013,  0.0927, -0.3905],\n",
      "        [ 0.9026, -0.5320, -0.6792, -0.4482]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1032, -0.7940, -0.5341,  0.1336],\n",
      "        [ 0.6960, -0.2135,  0.1095, -0.2886],\n",
      "        [ 0.0126, -0.3065, -0.1515,  0.8448],\n",
      "        [ 0.6460,  0.4994,  0.5028,  0.6675]], grad_fn=<TanhBackward0>), tensor([[-0.4393,  0.9624, -0.6006, -0.3952],\n",
      "        [ 0.5278,  0.7725, -0.9469, -0.2592],\n",
      "        [ 0.2889,  0.6014,  0.0928, -0.3907],\n",
      "        [ 0.9027, -0.5321, -0.6792, -0.4482]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1031, -0.7940, -0.5341,  0.1336],\n",
      "        [ 0.6960, -0.2135,  0.1094, -0.2887],\n",
      "        [ 0.0125, -0.3066, -0.1516,  0.8448],\n",
      "        [ 0.6460,  0.4994,  0.5028,  0.6675]], grad_fn=<TanhBackward0>), tensor([[-0.4394,  0.9625, -0.6007, -0.3954],\n",
      "        [ 0.5280,  0.7726, -0.9470, -0.2591],\n",
      "        [ 0.2890,  0.6015,  0.0930, -0.3909],\n",
      "        [ 0.9028, -0.5323, -0.6791, -0.4481]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1030, -0.7940, -0.5342,  0.1335],\n",
      "        [ 0.6959, -0.2136,  0.1094, -0.2887],\n",
      "        [ 0.0124, -0.3066, -0.1517,  0.8448],\n",
      "        [ 0.6460,  0.4994,  0.5028,  0.6675]], grad_fn=<TanhBackward0>), tensor([[-0.4395,  0.9625, -0.6008, -0.3955],\n",
      "        [ 0.5281,  0.7727, -0.9470, -0.2589],\n",
      "        [ 0.2891,  0.6015,  0.0931, -0.3910],\n",
      "        [ 0.9029, -0.5324, -0.6791, -0.4481]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1030, -0.7941, -0.5343,  0.1335],\n",
      "        [ 0.6959, -0.2136,  0.1093, -0.2887],\n",
      "        [ 0.0123, -0.3067, -0.1517,  0.8448],\n",
      "        [ 0.6460,  0.4994,  0.5028,  0.6675]], grad_fn=<TanhBackward0>), tensor([[-0.4396,  0.9625, -0.6008, -0.3956],\n",
      "        [ 0.5283,  0.7728, -0.9470, -0.2588],\n",
      "        [ 0.2891,  0.6016,  0.0932, -0.3912],\n",
      "        [ 0.9030, -0.5325, -0.6791, -0.4481]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1029, -0.7941, -0.5343,  0.1334],\n",
      "        [ 0.6959, -0.2136,  0.1093, -0.2887],\n",
      "        [ 0.0122, -0.3067, -0.1518,  0.8448],\n",
      "        [ 0.6460,  0.4995,  0.5027,  0.6676]], grad_fn=<TanhBackward0>), tensor([[-0.4397,  0.9625, -0.6009, -0.3957],\n",
      "        [ 0.5284,  0.7729, -0.9470, -0.2587],\n",
      "        [ 0.2892,  0.6017,  0.0933, -0.3914],\n",
      "        [ 0.9031, -0.5326, -0.6790, -0.4480]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1028, -0.7941, -0.5344,  0.1334],\n",
      "        [ 0.6959, -0.2136,  0.1093, -0.2888],\n",
      "        [ 0.0121, -0.3067, -0.1519,  0.8448],\n",
      "        [ 0.6460,  0.4995,  0.5027,  0.6676]], grad_fn=<TanhBackward0>), tensor([[-0.4398,  0.9625, -0.6009, -0.3958],\n",
      "        [ 0.5286,  0.7729, -0.9470, -0.2585],\n",
      "        [ 0.2893,  0.6017,  0.0934, -0.3916],\n",
      "        [ 0.9032, -0.5328, -0.6790, -0.4480]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1027, -0.7942, -0.5345,  0.1333],\n",
      "        [ 0.6959, -0.2137,  0.1092, -0.2888],\n",
      "        [ 0.0121, -0.3068, -0.1519,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5027,  0.6676]], grad_fn=<TanhBackward0>), tensor([[-0.4399,  0.9626, -0.6010, -0.3959],\n",
      "        [ 0.5287,  0.7730, -0.9470, -0.2584],\n",
      "        [ 0.2893,  0.6018,  0.0935, -0.3917],\n",
      "        [ 0.9033, -0.5329, -0.6789, -0.4479]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1026, -0.7942, -0.5345,  0.1333],\n",
      "        [ 0.6959, -0.2137,  0.1092, -0.2888],\n",
      "        [ 0.0120, -0.3068, -0.1520,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5027,  0.6676]], grad_fn=<TanhBackward0>), tensor([[-0.4400,  0.9626, -0.6011, -0.3960],\n",
      "        [ 0.5289,  0.7731, -0.9470, -0.2583],\n",
      "        [ 0.2894,  0.6019,  0.0936, -0.3919],\n",
      "        [ 0.9034, -0.5330, -0.6789, -0.4479]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1026, -0.7942, -0.5346,  0.1332],\n",
      "        [ 0.6959, -0.2137,  0.1091, -0.2888],\n",
      "        [ 0.0119, -0.3068, -0.1520,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5027,  0.6677]], grad_fn=<TanhBackward0>), tensor([[-0.4401,  0.9626, -0.6011, -0.3961],\n",
      "        [ 0.5290,  0.7732, -0.9471, -0.2582],\n",
      "        [ 0.2894,  0.6019,  0.0937, -0.3920],\n",
      "        [ 0.9035, -0.5331, -0.6789, -0.4479]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1025, -0.7942, -0.5347,  0.1332],\n",
      "        [ 0.6959, -0.2137,  0.1091, -0.2888],\n",
      "        [ 0.0118, -0.3069, -0.1521,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5027,  0.6677]], grad_fn=<TanhBackward0>), tensor([[-0.4402,  0.9626, -0.6012, -0.3962],\n",
      "        [ 0.5292,  0.7732, -0.9471, -0.2580],\n",
      "        [ 0.2895,  0.6020,  0.0938, -0.3922],\n",
      "        [ 0.9036, -0.5332, -0.6788, -0.4478]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1024, -0.7943, -0.5347,  0.1331],\n",
      "        [ 0.6959, -0.2138,  0.1090, -0.2889],\n",
      "        [ 0.0118, -0.3069, -0.1522,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5027,  0.6677]], grad_fn=<TanhBackward0>), tensor([[-0.4402,  0.9627, -0.6012, -0.3963],\n",
      "        [ 0.5293,  0.7733, -0.9471, -0.2579],\n",
      "        [ 0.2895,  0.6021,  0.0939, -0.3923],\n",
      "        [ 0.9037, -0.5333, -0.6788, -0.4478]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1023, -0.7943, -0.5348,  0.1331],\n",
      "        [ 0.6959, -0.2138,  0.1090, -0.2889],\n",
      "        [ 0.0117, -0.3069, -0.1522,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5027,  0.6677]], grad_fn=<TanhBackward0>), tensor([[-0.4403,  0.9627, -0.6013, -0.3963],\n",
      "        [ 0.5294,  0.7734, -0.9471, -0.2578],\n",
      "        [ 0.2896,  0.6021,  0.0940, -0.3925],\n",
      "        [ 0.9038, -0.5334, -0.6787, -0.4478]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1023, -0.7943, -0.5348,  0.1330],\n",
      "        [ 0.6959, -0.2138,  0.1090, -0.2889],\n",
      "        [ 0.0116, -0.3070, -0.1523,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5027,  0.6677]], grad_fn=<TanhBackward0>), tensor([[-0.4404,  0.9627, -0.6013, -0.3964],\n",
      "        [ 0.5296,  0.7734, -0.9471, -0.2577],\n",
      "        [ 0.2896,  0.6022,  0.0941, -0.3926],\n",
      "        [ 0.9039, -0.5335, -0.6787, -0.4477]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1022, -0.7943, -0.5349,  0.1330],\n",
      "        [ 0.6959, -0.2138,  0.1089, -0.2889],\n",
      "        [ 0.0116, -0.3070, -0.1523,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5027,  0.6678]], grad_fn=<TanhBackward0>), tensor([[-0.4405,  0.9627, -0.6014, -0.3965],\n",
      "        [ 0.5297,  0.7735, -0.9471, -0.2576],\n",
      "        [ 0.2897,  0.6022,  0.0942, -0.3927],\n",
      "        [ 0.9039, -0.5336, -0.6787, -0.4477]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1021, -0.7944, -0.5350,  0.1329],\n",
      "        [ 0.6959, -0.2138,  0.1089, -0.2889],\n",
      "        [ 0.0115, -0.3070, -0.1524,  0.8448],\n",
      "        [ 0.6459,  0.4995,  0.5026,  0.6678]], grad_fn=<TanhBackward0>), tensor([[-0.4405,  0.9627, -0.6014, -0.3966],\n",
      "        [ 0.5298,  0.7735, -0.9471, -0.2575],\n",
      "        [ 0.2897,  0.6023,  0.0943, -0.3929],\n",
      "        [ 0.9040, -0.5337, -0.6786, -0.4477]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1021, -0.7944, -0.5350,  0.1329],\n",
      "        [ 0.6958, -0.2139,  0.1089, -0.2890],\n",
      "        [ 0.0115, -0.3070, -0.1524,  0.8448],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6678]], grad_fn=<TanhBackward0>), tensor([[-0.4406,  0.9628, -0.6014, -0.3967],\n",
      "        [ 0.5299,  0.7736, -0.9471, -0.2574],\n",
      "        [ 0.2898,  0.6023,  0.0944, -0.3930],\n",
      "        [ 0.9041, -0.5338, -0.6786, -0.4476]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1020, -0.7944, -0.5351,  0.1329],\n",
      "        [ 0.6958, -0.2139,  0.1088, -0.2890],\n",
      "        [ 0.0114, -0.3071, -0.1525,  0.8448],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6678]], grad_fn=<TanhBackward0>), tensor([[-0.4407,  0.9628, -0.6015, -0.3967],\n",
      "        [ 0.5300,  0.7736, -0.9472, -0.2573],\n",
      "        [ 0.2898,  0.6024,  0.0944, -0.3931],\n",
      "        [ 0.9042, -0.5338, -0.6786, -0.4476]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1020, -0.7944, -0.5351,  0.1328],\n",
      "        [ 0.6958, -0.2139,  0.1088, -0.2890],\n",
      "        [ 0.0113, -0.3071, -0.1525,  0.8448],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6678]], grad_fn=<TanhBackward0>), tensor([[-0.4407,  0.9628, -0.6015, -0.3968],\n",
      "        [ 0.5301,  0.7737, -0.9472, -0.2572],\n",
      "        [ 0.2899,  0.6024,  0.0945, -0.3932],\n",
      "        [ 0.9042, -0.5339, -0.6785, -0.4476]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1019, -0.7944, -0.5351,  0.1328],\n",
      "        [ 0.6958, -0.2139,  0.1088, -0.2890],\n",
      "        [ 0.0113, -0.3071, -0.1525,  0.8449],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6678]], grad_fn=<TanhBackward0>), tensor([[-0.4408,  0.9628, -0.6016, -0.3969],\n",
      "        [ 0.5302,  0.7738, -0.9472, -0.2571],\n",
      "        [ 0.2899,  0.6025,  0.0946, -0.3934],\n",
      "        [ 0.9043, -0.5340, -0.6785, -0.4476]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1018, -0.7945, -0.5352,  0.1327],\n",
      "        [ 0.6958, -0.2139,  0.1087, -0.2890],\n",
      "        [ 0.0112, -0.3071, -0.1526,  0.8449],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6679]], grad_fn=<TanhBackward0>), tensor([[-0.4409,  0.9628, -0.6016, -0.3969],\n",
      "        [ 0.5303,  0.7738, -0.9472, -0.2570],\n",
      "        [ 0.2899,  0.6025,  0.0947, -0.3935],\n",
      "        [ 0.9044, -0.5341, -0.6785, -0.4475]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1018, -0.7945, -0.5352,  0.1327],\n",
      "        [ 0.6958, -0.2139,  0.1087, -0.2890],\n",
      "        [ 0.0112, -0.3072, -0.1526,  0.8449],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6679]], grad_fn=<TanhBackward0>), tensor([[-0.4409,  0.9628, -0.6017, -0.3970],\n",
      "        [ 0.5304,  0.7739, -0.9472, -0.2569],\n",
      "        [ 0.2900,  0.6026,  0.0947, -0.3936],\n",
      "        [ 0.9044, -0.5342, -0.6785, -0.4475]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1017, -0.7945, -0.5353,  0.1327],\n",
      "        [ 0.6958, -0.2140,  0.1087, -0.2890],\n",
      "        [ 0.0111, -0.3072, -0.1527,  0.8449],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6679]], grad_fn=<TanhBackward0>), tensor([[-0.4410,  0.9628, -0.6017, -0.3971],\n",
      "        [ 0.5305,  0.7739, -0.9472, -0.2569],\n",
      "        [ 0.2900,  0.6026,  0.0948, -0.3937],\n",
      "        [ 0.9045, -0.5342, -0.6784, -0.4475]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1017, -0.7945, -0.5353,  0.1326],\n",
      "        [ 0.6958, -0.2140,  0.1087, -0.2891],\n",
      "        [ 0.0111, -0.3072, -0.1527,  0.8449],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6679]], grad_fn=<TanhBackward0>), tensor([[-0.4411,  0.9629, -0.6017, -0.3971],\n",
      "        [ 0.5306,  0.7739, -0.9472, -0.2568],\n",
      "        [ 0.2901,  0.6027,  0.0949, -0.3938],\n",
      "        [ 0.9045, -0.5343, -0.6784, -0.4474]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1016, -0.7945, -0.5354,  0.1326],\n",
      "        [ 0.6958, -0.2140,  0.1086, -0.2891],\n",
      "        [ 0.0110, -0.3072, -0.1528,  0.8449],\n",
      "        [ 0.6459,  0.4996,  0.5026,  0.6679]], grad_fn=<TanhBackward0>), tensor([[-0.4411,  0.9629, -0.6018, -0.3972],\n",
      "        [ 0.5307,  0.7740, -0.9472, -0.2567],\n",
      "        [ 0.2901,  0.6027,  0.0949, -0.3939],\n",
      "        [ 0.9046, -0.5344, -0.6784, -0.4474]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1016, -0.7946, -0.5354,  0.1326],\n",
      "        [ 0.6958, -0.2140,  0.1086, -0.2891],\n",
      "        [ 0.0110, -0.3073, -0.1528,  0.8449],\n",
      "        [ 0.6458,  0.4996,  0.5026,  0.6679]], grad_fn=<TanhBackward0>), tensor([[-0.4412,  0.9629, -0.6018, -0.3973],\n",
      "        [ 0.5308,  0.7740, -0.9472, -0.2566],\n",
      "        [ 0.2901,  0.6027,  0.0950, -0.3940],\n",
      "        [ 0.9047, -0.5345, -0.6784, -0.4474]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1015, -0.7946, -0.5354,  0.1325],\n",
      "        [ 0.6958, -0.2140,  0.1086, -0.2891],\n",
      "        [ 0.0109, -0.3073, -0.1528,  0.8449],\n",
      "        [ 0.6458,  0.4996,  0.5026,  0.6679]], grad_fn=<TanhBackward0>), tensor([[-0.4412,  0.9629, -0.6018, -0.3973],\n",
      "        [ 0.5309,  0.7741, -0.9472, -0.2565],\n",
      "        [ 0.2902,  0.6028,  0.0951, -0.3941],\n",
      "        [ 0.9047, -0.5345, -0.6783, -0.4474]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1015, -0.7946, -0.5355,  0.1325],\n",
      "        [ 0.6958, -0.2140,  0.1085, -0.2891],\n",
      "        [ 0.0109, -0.3073, -0.1529,  0.8449],\n",
      "        [ 0.6458,  0.4996,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4413,  0.9629, -0.6019, -0.3974],\n",
      "        [ 0.5310,  0.7741, -0.9473, -0.2565],\n",
      "        [ 0.2902,  0.6028,  0.0951, -0.3942],\n",
      "        [ 0.9048, -0.5346, -0.6783, -0.4474]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1014, -0.7946, -0.5355,  0.1325],\n",
      "        [ 0.6958, -0.2140,  0.1085, -0.2891],\n",
      "        [ 0.0108, -0.3073, -0.1529,  0.8449],\n",
      "        [ 0.6458,  0.4996,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4413,  0.9629, -0.6019, -0.3974],\n",
      "        [ 0.5311,  0.7742, -0.9473, -0.2564],\n",
      "        [ 0.2902,  0.6029,  0.0952, -0.3943],\n",
      "        [ 0.9048, -0.5347, -0.6783, -0.4473]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1014, -0.7946, -0.5356,  0.1325],\n",
      "        [ 0.6958, -0.2141,  0.1085, -0.2891],\n",
      "        [ 0.0108, -0.3073, -0.1529,  0.8449],\n",
      "        [ 0.6458,  0.4996,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4414,  0.9629, -0.6019, -0.3975],\n",
      "        [ 0.5312,  0.7742, -0.9473, -0.2563],\n",
      "        [ 0.2903,  0.6029,  0.0952, -0.3944],\n",
      "        [ 0.9049, -0.5347, -0.6783, -0.4473]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1014, -0.7946, -0.5356,  0.1324],\n",
      "        [ 0.6958, -0.2141,  0.1085, -0.2891],\n",
      "        [ 0.0108, -0.3074, -0.1530,  0.8449],\n",
      "        [ 0.6458,  0.4996,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4414,  0.9630, -0.6020, -0.3975],\n",
      "        [ 0.5312,  0.7742, -0.9473, -0.2563],\n",
      "        [ 0.2903,  0.6029,  0.0953, -0.3944],\n",
      "        [ 0.9049, -0.5348, -0.6782, -0.4473]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1013, -0.7947, -0.5356,  0.1324],\n",
      "        [ 0.6958, -0.2141,  0.1085, -0.2892],\n",
      "        [ 0.0107, -0.3074, -0.1530,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4415,  0.9630, -0.6020, -0.3976],\n",
      "        [ 0.5313,  0.7743, -0.9473, -0.2562],\n",
      "        [ 0.2903,  0.6030,  0.0954, -0.3945],\n",
      "        [ 0.9050, -0.5348, -0.6782, -0.4473]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1013, -0.7947, -0.5357,  0.1324],\n",
      "        [ 0.6958, -0.2141,  0.1084, -0.2892],\n",
      "        [ 0.0107, -0.3074, -0.1530,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4415,  0.9630, -0.6020, -0.3976],\n",
      "        [ 0.5314,  0.7743, -0.9473, -0.2561],\n",
      "        [ 0.2903,  0.6030,  0.0954, -0.3946],\n",
      "        [ 0.9050, -0.5349, -0.6782, -0.4473]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1012, -0.7947, -0.5357,  0.1323],\n",
      "        [ 0.6958, -0.2141,  0.1084, -0.2892],\n",
      "        [ 0.0106, -0.3074, -0.1531,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4415,  0.9630, -0.6020, -0.3977],\n",
      "        [ 0.5315,  0.7743, -0.9473, -0.2561],\n",
      "        [ 0.2904,  0.6030,  0.0955, -0.3947],\n",
      "        [ 0.9051, -0.5349, -0.6782, -0.4472]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1012, -0.7947, -0.5357,  0.1323],\n",
      "        [ 0.6958, -0.2141,  0.1084, -0.2892],\n",
      "        [ 0.0106, -0.3074, -0.1531,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4416,  0.9630, -0.6021, -0.3977],\n",
      "        [ 0.5315,  0.7744, -0.9473, -0.2560],\n",
      "        [ 0.2904,  0.6031,  0.0955, -0.3948],\n",
      "        [ 0.9051, -0.5350, -0.6782, -0.4472]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1012, -0.7947, -0.5358,  0.1323],\n",
      "        [ 0.6958, -0.2141,  0.1084, -0.2892],\n",
      "        [ 0.0106, -0.3074, -0.1531,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6680]], grad_fn=<TanhBackward0>), tensor([[-0.4416,  0.9630, -0.6021, -0.3978],\n",
      "        [ 0.5316,  0.7744, -0.9473, -0.2559],\n",
      "        [ 0.2904,  0.6031,  0.0956, -0.3948],\n",
      "        [ 0.9051, -0.5351, -0.6781, -0.4472]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1011, -0.7947, -0.5358,  0.1323],\n",
      "        [ 0.6957, -0.2141,  0.1083, -0.2892],\n",
      "        [ 0.0105, -0.3075, -0.1531,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4417,  0.9630, -0.6021, -0.3978],\n",
      "        [ 0.5317,  0.7744, -0.9473, -0.2559],\n",
      "        [ 0.2905,  0.6031,  0.0956, -0.3949],\n",
      "        [ 0.9052, -0.5351, -0.6781, -0.4472]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1011, -0.7947, -0.5358,  0.1322],\n",
      "        [ 0.6957, -0.2141,  0.1083, -0.2892],\n",
      "        [ 0.0105, -0.3075, -0.1532,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4417,  0.9630, -0.6021, -0.3979],\n",
      "        [ 0.5317,  0.7745, -0.9473, -0.2558],\n",
      "        [ 0.2905,  0.6031,  0.0957, -0.3950],\n",
      "        [ 0.9052, -0.5352, -0.6781, -0.4472]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1011, -0.7947, -0.5358,  0.1322],\n",
      "        [ 0.6957, -0.2142,  0.1083, -0.2892],\n",
      "        [ 0.0105, -0.3075, -0.1532,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4417,  0.9630, -0.6022, -0.3979],\n",
      "        [ 0.5318,  0.7745, -0.9473, -0.2558],\n",
      "        [ 0.2905,  0.6032,  0.0957, -0.3951],\n",
      "        [ 0.9053, -0.5352, -0.6781, -0.4471]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1010, -0.7948, -0.5359,  0.1322],\n",
      "        [ 0.6957, -0.2142,  0.1083, -0.2892],\n",
      "        [ 0.0104, -0.3075, -0.1532,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4418,  0.9630, -0.6022, -0.3979],\n",
      "        [ 0.5319,  0.7745, -0.9473, -0.2557],\n",
      "        [ 0.2905,  0.6032,  0.0957, -0.3951],\n",
      "        [ 0.9053, -0.5353, -0.6781, -0.4471]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1010, -0.7948, -0.5359,  0.1322],\n",
      "        [ 0.6957, -0.2142,  0.1083, -0.2892],\n",
      "        [ 0.0104, -0.3075, -0.1532,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4418,  0.9631, -0.6022, -0.3980],\n",
      "        [ 0.5319,  0.7746, -0.9473, -0.2557],\n",
      "        [ 0.2906,  0.6032,  0.0958, -0.3952],\n",
      "        [ 0.9053, -0.5353, -0.6781, -0.4471]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1010, -0.7948, -0.5359,  0.1322],\n",
      "        [ 0.6957, -0.2142,  0.1083, -0.2892],\n",
      "        [ 0.0104, -0.3075, -0.1533,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4419,  0.9631, -0.6022, -0.3980],\n",
      "        [ 0.5320,  0.7746, -0.9474, -0.2556],\n",
      "        [ 0.2906,  0.6033,  0.0958, -0.3953],\n",
      "        [ 0.9054, -0.5353, -0.6780, -0.4471]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1009, -0.7948, -0.5359,  0.1321],\n",
      "        [ 0.6957, -0.2142,  0.1082, -0.2893],\n",
      "        [ 0.0103, -0.3075, -0.1533,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4419,  0.9631, -0.6023, -0.3980],\n",
      "        [ 0.5320,  0.7746, -0.9474, -0.2556],\n",
      "        [ 0.2906,  0.6033,  0.0959, -0.3953],\n",
      "        [ 0.9054, -0.5354, -0.6780, -0.4471]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1009, -0.7948, -0.5360,  0.1321],\n",
      "        [ 0.6957, -0.2142,  0.1082, -0.2893],\n",
      "        [ 0.0103, -0.3076, -0.1533,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4419,  0.9631, -0.6023, -0.3981],\n",
      "        [ 0.5321,  0.7747, -0.9474, -0.2555],\n",
      "        [ 0.2906,  0.6033,  0.0959, -0.3954],\n",
      "        [ 0.9055, -0.5354, -0.6780, -0.4471]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1009, -0.7948, -0.5360,  0.1321],\n",
      "        [ 0.6957, -0.2142,  0.1082, -0.2893],\n",
      "        [ 0.0103, -0.3076, -0.1533,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4420,  0.9631, -0.6023, -0.3981],\n",
      "        [ 0.5322,  0.7747, -0.9474, -0.2555],\n",
      "        [ 0.2906,  0.6033,  0.0959, -0.3954],\n",
      "        [ 0.9055, -0.5355, -0.6780, -0.4471]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1008, -0.7948, -0.5360,  0.1321],\n",
      "        [ 0.6957, -0.2142,  0.1082, -0.2893],\n",
      "        [ 0.0103, -0.3076, -0.1534,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4420,  0.9631, -0.6023, -0.3982],\n",
      "        [ 0.5322,  0.7747, -0.9474, -0.2554],\n",
      "        [ 0.2907,  0.6033,  0.0960, -0.3955],\n",
      "        [ 0.9055, -0.5355, -0.6780, -0.4470]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1008, -0.7948, -0.5360,  0.1321],\n",
      "        [ 0.6957, -0.2142,  0.1082, -0.2893],\n",
      "        [ 0.0102, -0.3076, -0.1534,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5025,  0.6681]], grad_fn=<TanhBackward0>), tensor([[-0.4420,  0.9631, -0.6023, -0.3982],\n",
      "        [ 0.5323,  0.7747, -0.9474, -0.2554],\n",
      "        [ 0.2907,  0.6034,  0.0960, -0.3955],\n",
      "        [ 0.9056, -0.5355, -0.6780, -0.4470]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1008, -0.7948, -0.5361,  0.1321],\n",
      "        [ 0.6957, -0.2142,  0.1082, -0.2893],\n",
      "        [ 0.0102, -0.3076, -0.1534,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4420,  0.9631, -0.6024, -0.3982],\n",
      "        [ 0.5323,  0.7748, -0.9474, -0.2553],\n",
      "        [ 0.2907,  0.6034,  0.0961, -0.3956],\n",
      "        [ 0.9056, -0.5356, -0.6780, -0.4470]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1008, -0.7948, -0.5361,  0.1320],\n",
      "        [ 0.6957, -0.2142,  0.1082, -0.2893],\n",
      "        [ 0.0102, -0.3076, -0.1534,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4421,  0.9631, -0.6024, -0.3982],\n",
      "        [ 0.5324,  0.7748, -0.9474, -0.2553],\n",
      "        [ 0.2907,  0.6034,  0.0961, -0.3957],\n",
      "        [ 0.9056, -0.5356, -0.6779, -0.4470]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1007, -0.7949, -0.5361,  0.1320],\n",
      "        [ 0.6957, -0.2142,  0.1081, -0.2893],\n",
      "        [ 0.0102, -0.3076, -0.1534,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4421,  0.9631, -0.6024, -0.3983],\n",
      "        [ 0.5324,  0.7748, -0.9474, -0.2552],\n",
      "        [ 0.2907,  0.6034,  0.0961, -0.3957],\n",
      "        [ 0.9056, -0.5357, -0.6779, -0.4470]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1007, -0.7949, -0.5361,  0.1320],\n",
      "        [ 0.6957, -0.2143,  0.1081, -0.2893],\n",
      "        [ 0.0101, -0.3076, -0.1535,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4421,  0.9631, -0.6024, -0.3983],\n",
      "        [ 0.5325,  0.7748, -0.9474, -0.2552],\n",
      "        [ 0.2908,  0.6035,  0.0962, -0.3958],\n",
      "        [ 0.9057, -0.5357, -0.6779, -0.4470]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1007, -0.7949, -0.5361,  0.1320],\n",
      "        [ 0.6957, -0.2143,  0.1081, -0.2893],\n",
      "        [ 0.0101, -0.3077, -0.1535,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4422,  0.9631, -0.6024, -0.3983],\n",
      "        [ 0.5325,  0.7748, -0.9474, -0.2552],\n",
      "        [ 0.2908,  0.6035,  0.0962, -0.3958],\n",
      "        [ 0.9057, -0.5357, -0.6779, -0.4470]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1007, -0.7949, -0.5362,  0.1320],\n",
      "        [ 0.6957, -0.2143,  0.1081, -0.2893],\n",
      "        [ 0.0101, -0.3077, -0.1535,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4422,  0.9631, -0.6024, -0.3984],\n",
      "        [ 0.5325,  0.7749, -0.9474, -0.2551],\n",
      "        [ 0.2908,  0.6035,  0.0962, -0.3959],\n",
      "        [ 0.9057, -0.5358, -0.6779, -0.4470]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1006, -0.7949, -0.5362,  0.1320],\n",
      "        [ 0.6957, -0.2143,  0.1081, -0.2893],\n",
      "        [ 0.0101, -0.3077, -0.1535,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4422,  0.9632, -0.6025, -0.3984],\n",
      "        [ 0.5326,  0.7749, -0.9474, -0.2551],\n",
      "        [ 0.2908,  0.6035,  0.0963, -0.3959],\n",
      "        [ 0.9058, -0.5358, -0.6779, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1006, -0.7949, -0.5362,  0.1319],\n",
      "        [ 0.6957, -0.2143,  0.1081, -0.2893],\n",
      "        [ 0.0100, -0.3077, -0.1535,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4422,  0.9632, -0.6025, -0.3984],\n",
      "        [ 0.5326,  0.7749, -0.9474, -0.2550],\n",
      "        [ 0.2908,  0.6035,  0.0963, -0.3959],\n",
      "        [ 0.9058, -0.5358, -0.6779, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1006, -0.7949, -0.5362,  0.1319],\n",
      "        [ 0.6957, -0.2143,  0.1081, -0.2893],\n",
      "        [ 0.0100, -0.3077, -0.1536,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4423,  0.9632, -0.6025, -0.3984],\n",
      "        [ 0.5327,  0.7749, -0.9474, -0.2550],\n",
      "        [ 0.2908,  0.6036,  0.0963, -0.3960],\n",
      "        [ 0.9058, -0.5359, -0.6779, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1006, -0.7949, -0.5362,  0.1319],\n",
      "        [ 0.6957, -0.2143,  0.1081, -0.2893],\n",
      "        [ 0.0100, -0.3077, -0.1536,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4423,  0.9632, -0.6025, -0.3985],\n",
      "        [ 0.5327,  0.7749, -0.9474, -0.2550],\n",
      "        [ 0.2909,  0.6036,  0.0963, -0.3960],\n",
      "        [ 0.9058, -0.5359, -0.6778, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1005, -0.7949, -0.5363,  0.1319],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0100, -0.3077, -0.1536,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4423,  0.9632, -0.6025, -0.3985],\n",
      "        [ 0.5327,  0.7750, -0.9474, -0.2549],\n",
      "        [ 0.2909,  0.6036,  0.0964, -0.3961],\n",
      "        [ 0.9058, -0.5359, -0.6778, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1005, -0.7949, -0.5363,  0.1319],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0100, -0.3077, -0.1536,  0.8449],\n",
      "        [ 0.6458,  0.4997,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4423,  0.9632, -0.6025, -0.3985],\n",
      "        [ 0.5328,  0.7750, -0.9474, -0.2549],\n",
      "        [ 0.2909,  0.6036,  0.0964, -0.3961],\n",
      "        [ 0.9059, -0.5359, -0.6778, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1005, -0.7949, -0.5363,  0.1319],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0099, -0.3077, -0.1536,  0.8449],\n",
      "        [ 0.6458,  0.4998,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4423,  0.9632, -0.6025, -0.3985],\n",
      "        [ 0.5328,  0.7750, -0.9474, -0.2549],\n",
      "        [ 0.2909,  0.6036,  0.0964, -0.3962],\n",
      "        [ 0.9059, -0.5360, -0.6778, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1005, -0.7949, -0.5363,  0.1319],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0099, -0.3077, -0.1536,  0.8449],\n",
      "        [ 0.6458,  0.4998,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4424,  0.9632, -0.6026, -0.3986],\n",
      "        [ 0.5329,  0.7750, -0.9474, -0.2548],\n",
      "        [ 0.2909,  0.6036,  0.0964, -0.3962],\n",
      "        [ 0.9059, -0.5360, -0.6778, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1005, -0.7949, -0.5363,  0.1319],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0099, -0.3077, -0.1536,  0.8449],\n",
      "        [ 0.6458,  0.4998,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4424,  0.9632, -0.6026, -0.3986],\n",
      "        [ 0.5329,  0.7750, -0.9474, -0.2548],\n",
      "        [ 0.2909,  0.6036,  0.0965, -0.3962],\n",
      "        [ 0.9059, -0.5360, -0.6778, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1005, -0.7950, -0.5363,  0.1318],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0099, -0.3078, -0.1537,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4424,  0.9632, -0.6026, -0.3986],\n",
      "        [ 0.5329,  0.7750, -0.9474, -0.2548],\n",
      "        [ 0.2909,  0.6037,  0.0965, -0.3963],\n",
      "        [ 0.9060, -0.5360, -0.6778, -0.4469]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1004, -0.7950, -0.5363,  0.1318],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0099, -0.3078, -0.1537,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6682]], grad_fn=<TanhBackward0>), tensor([[-0.4424,  0.9632, -0.6026, -0.3986],\n",
      "        [ 0.5330,  0.7751, -0.9474, -0.2548],\n",
      "        [ 0.2909,  0.6037,  0.0965, -0.3963],\n",
      "        [ 0.9060, -0.5361, -0.6778, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1004, -0.7950, -0.5364,  0.1318],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0099, -0.3078, -0.1537,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4424,  0.9632, -0.6026, -0.3986],\n",
      "        [ 0.5330,  0.7751, -0.9474, -0.2547],\n",
      "        [ 0.2910,  0.6037,  0.0965, -0.3963],\n",
      "        [ 0.9060, -0.5361, -0.6778, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1004, -0.7950, -0.5364,  0.1318],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0098, -0.3078, -0.1537,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4425,  0.9632, -0.6026, -0.3987],\n",
      "        [ 0.5330,  0.7751, -0.9475, -0.2547],\n",
      "        [ 0.2910,  0.6037,  0.0966, -0.3964],\n",
      "        [ 0.9060, -0.5361, -0.6778, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1004, -0.7950, -0.5364,  0.1318],\n",
      "        [ 0.6957, -0.2143,  0.1080, -0.2894],\n",
      "        [ 0.0098, -0.3078, -0.1537,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4425,  0.9632, -0.6026, -0.3987],\n",
      "        [ 0.5330,  0.7751, -0.9475, -0.2547],\n",
      "        [ 0.2910,  0.6037,  0.0966, -0.3964],\n",
      "        [ 0.9060, -0.5361, -0.6778, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1004, -0.7950, -0.5364,  0.1318],\n",
      "        [ 0.6957, -0.2143,  0.1079, -0.2894],\n",
      "        [ 0.0098, -0.3078, -0.1537,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4425,  0.9632, -0.6026, -0.3987],\n",
      "        [ 0.5331,  0.7751, -0.9475, -0.2546],\n",
      "        [ 0.2910,  0.6037,  0.0966, -0.3964],\n",
      "        [ 0.9061, -0.5362, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1004, -0.7950, -0.5364,  0.1318],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0098, -0.3078, -0.1537,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4425,  0.9632, -0.6027, -0.3987],\n",
      "        [ 0.5331,  0.7751, -0.9475, -0.2546],\n",
      "        [ 0.2910,  0.6037,  0.0966, -0.3965],\n",
      "        [ 0.9061, -0.5362, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [300/1000], Loss: 7.664046279387549e-06\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1003, -0.7950, -0.5364,  0.1318],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0098, -0.3078, -0.1537,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4425,  0.9632, -0.6027, -0.3987],\n",
      "        [ 0.5331,  0.7752, -0.9475, -0.2546],\n",
      "        [ 0.2910,  0.6038,  0.0966, -0.3965],\n",
      "        [ 0.9061, -0.5362, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1003, -0.7950, -0.5364,  0.1318],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0098, -0.3078, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4425,  0.9632, -0.6027, -0.3988],\n",
      "        [ 0.5332,  0.7752, -0.9475, -0.2546],\n",
      "        [ 0.2910,  0.6038,  0.0967, -0.3965],\n",
      "        [ 0.9061, -0.5362, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1003, -0.7950, -0.5364,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0098, -0.3078, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4426,  0.9632, -0.6027, -0.3988],\n",
      "        [ 0.5332,  0.7752, -0.9475, -0.2546],\n",
      "        [ 0.2910,  0.6038,  0.0967, -0.3965],\n",
      "        [ 0.9061, -0.5362, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1003, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0097, -0.3078, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4426,  0.9632, -0.6027, -0.3988],\n",
      "        [ 0.5332,  0.7752, -0.9475, -0.2545],\n",
      "        [ 0.2910,  0.6038,  0.0967, -0.3966],\n",
      "        [ 0.9061, -0.5363, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1003, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0097, -0.3078, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4426,  0.9633, -0.6027, -0.3988],\n",
      "        [ 0.5332,  0.7752, -0.9475, -0.2545],\n",
      "        [ 0.2911,  0.6038,  0.0967, -0.3966],\n",
      "        [ 0.9061, -0.5363, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1003, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0097, -0.3078, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4426,  0.9633, -0.6027, -0.3988],\n",
      "        [ 0.5333,  0.7752, -0.9475, -0.2545],\n",
      "        [ 0.2911,  0.6038,  0.0967, -0.3966],\n",
      "        [ 0.9062, -0.5363, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1003, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0097, -0.3078, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4426,  0.9633, -0.6027, -0.3988],\n",
      "        [ 0.5333,  0.7752, -0.9475, -0.2545],\n",
      "        [ 0.2911,  0.6038,  0.0967, -0.3967],\n",
      "        [ 0.9062, -0.5363, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0097, -0.3078, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4426,  0.9633, -0.6027, -0.3988],\n",
      "        [ 0.5333,  0.7752, -0.9475, -0.2544],\n",
      "        [ 0.2911,  0.6038,  0.0968, -0.3967],\n",
      "        [ 0.9062, -0.5363, -0.6777, -0.4468]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0097, -0.3078, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4426,  0.9633, -0.6027, -0.3989],\n",
      "        [ 0.5333,  0.7752, -0.9475, -0.2544],\n",
      "        [ 0.2911,  0.6038,  0.0968, -0.3967],\n",
      "        [ 0.9062, -0.5363, -0.6777, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0097, -0.3079, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6027, -0.3989],\n",
      "        [ 0.5333,  0.7753, -0.9475, -0.2544],\n",
      "        [ 0.2911,  0.6039,  0.0968, -0.3967],\n",
      "        [ 0.9062, -0.5364, -0.6777, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0097, -0.3079, -0.1538,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6028, -0.3989],\n",
      "        [ 0.5334,  0.7753, -0.9475, -0.2544],\n",
      "        [ 0.2911,  0.6039,  0.0968, -0.3967],\n",
      "        [ 0.9062, -0.5364, -0.6777, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1079, -0.2894],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6028, -0.3989],\n",
      "        [ 0.5334,  0.7753, -0.9475, -0.2544],\n",
      "        [ 0.2911,  0.6039,  0.0968, -0.3968],\n",
      "        [ 0.9062, -0.5364, -0.6777, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7950, -0.5365,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1078, -0.2894],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6028, -0.3989],\n",
      "        [ 0.5334,  0.7753, -0.9475, -0.2544],\n",
      "        [ 0.2911,  0.6039,  0.0968, -0.3968],\n",
      "        [ 0.9063, -0.5364, -0.6777, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7950, -0.5366,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1078, -0.2894],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6028, -0.3989],\n",
      "        [ 0.5334,  0.7753, -0.9475, -0.2543],\n",
      "        [ 0.2911,  0.6039,  0.0968, -0.3968],\n",
      "        [ 0.9063, -0.5364, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7951, -0.5366,  0.1317],\n",
      "        [ 0.6957, -0.2144,  0.1078, -0.2894],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6028, -0.3989],\n",
      "        [ 0.5334,  0.7753, -0.9475, -0.2543],\n",
      "        [ 0.2911,  0.6039,  0.0969, -0.3968],\n",
      "        [ 0.9063, -0.5364, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6957, -0.2144,  0.1078, -0.2894],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5335,  0.7753, -0.9475, -0.2543],\n",
      "        [ 0.2911,  0.6039,  0.0969, -0.3969],\n",
      "        [ 0.9063, -0.5365, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1002, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5335,  0.7753, -0.9475, -0.2543],\n",
      "        [ 0.2912,  0.6039,  0.0969, -0.3969],\n",
      "        [ 0.9063, -0.5365, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4427,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5335,  0.7753, -0.9475, -0.2543],\n",
      "        [ 0.2912,  0.6039,  0.0969, -0.3969],\n",
      "        [ 0.9063, -0.5365, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5335,  0.7753, -0.9475, -0.2543],\n",
      "        [ 0.2912,  0.6039,  0.0969, -0.3969],\n",
      "        [ 0.9063, -0.5365, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5335,  0.7753, -0.9475, -0.2542],\n",
      "        [ 0.2912,  0.6039,  0.0969, -0.3969],\n",
      "        [ 0.9063, -0.5365, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5335,  0.7754, -0.9475, -0.2542],\n",
      "        [ 0.2912,  0.6039,  0.0969, -0.3969],\n",
      "        [ 0.9063, -0.5365, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0096, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5024,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5336,  0.7754, -0.9475, -0.2542],\n",
      "        [ 0.2912,  0.6039,  0.0969, -0.3970],\n",
      "        [ 0.9064, -0.5365, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5336,  0.7754, -0.9475, -0.2542],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3970],\n",
      "        [ 0.9064, -0.5365, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5336,  0.7754, -0.9475, -0.2542],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3970],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1539,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6028, -0.3990],\n",
      "        [ 0.5336,  0.7754, -0.9475, -0.2542],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3970],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6683]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5336,  0.7754, -0.9475, -0.2542],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3970],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5336,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3970],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5366,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5336,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3971],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1001, -0.7951, -0.5367,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4428,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5337,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3971],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5337,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3971],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5337,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3971],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5337,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3971],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4467]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5337,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0970, -0.3971],\n",
      "        [ 0.9064, -0.5366, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1316],\n",
      "        [ 0.6956, -0.2144,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5337,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0971, -0.3971],\n",
      "        [ 0.9065, -0.5366, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1316],\n",
      "        [ 0.6956, -0.2145,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5337,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2912,  0.6040,  0.0971, -0.3971],\n",
      "        [ 0.9065, -0.5367, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1316],\n",
      "        [ 0.6956, -0.2145,  0.1078, -0.2895],\n",
      "        [ 0.0095, -0.3079, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5337,  0.7754, -0.9475, -0.2541],\n",
      "        [ 0.2913,  0.6040,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0095, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6040,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6040,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3991],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6040,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6040,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6040,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6776, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6041,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6041,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6041,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6041,  0.0971, -0.3972],\n",
      "        [ 0.9065, -0.5367, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4429,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6041,  0.0971, -0.3973],\n",
      "        [ 0.9065, -0.5367, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6041,  0.0971, -0.3973],\n",
      "        [ 0.9065, -0.5367, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.1000, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1540,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5338,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6041,  0.0971, -0.3973],\n",
      "        [ 0.9065, -0.5367, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2540],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9065, -0.5367, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9065, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9065, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5367,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9065, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9633, -0.6029, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3973],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3992],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0094, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5339,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7755, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7951, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2539],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5368, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2913,  0.6041,  0.0972, -0.3974],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2913,  0.6041,  0.0973, -0.3974],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6041,  0.0973, -0.3974],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4430,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6041,  0.0973, -0.3974],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6041,  0.0973, -0.3974],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6041,  0.0973, -0.3974],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6041,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9475, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1315],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0999, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9066, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5340,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [400/1000], Loss: 3.442245954943246e-08\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2538],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4466]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3993],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1541,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1077, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3975],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5368,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5369, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [500/1000], Loss: 1.5704329503485326e-10\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [600/1000], Loss: 2.2633284135764598e-12\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [700/1000], Loss: 1.443845043525016e-12\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [800/1000], Loss: 1.091189638646739e-12\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "Epoch [900/1000], Loss: 9.618486562779083e-13\n",
      "Accuracy: 100.00%\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n",
      "0\n",
      "1\n",
      "Done with hidden activations [tensor([[ 0.0998, -0.7952, -0.5369,  0.1314],\n",
      "        [ 0.6956, -0.2145,  0.1076, -0.2895],\n",
      "        [ 0.0093, -0.3080, -0.1542,  0.8449],\n",
      "        [ 0.6457,  0.4998,  0.5023,  0.6684]], grad_fn=<TanhBackward0>), tensor([[-0.4431,  0.9634, -0.6030, -0.3994],\n",
      "        [ 0.5341,  0.7756, -0.9476, -0.2537],\n",
      "        [ 0.2914,  0.6042,  0.0973, -0.3976],\n",
      "        [ 0.9067, -0.5370, -0.6775, -0.4465]], grad_fn=<TanhBackward0>)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage with XOR data\n",
    "input_size = 2  # XOR has two input features (0 or 1)\n",
    "hidden_size = 4  # Hidden layers size\n",
    "hidden_layers_number = 1 # Number of hidden layers\n",
    "output_size = 1  # XOR has one output feature (0 or 1)\n",
    "# Define XOR inputs and targets\n",
    "data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)  # XOR inputs\n",
    "targets = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)  # XOR targets\n",
    "\n",
    "# Initialize the model and loss function\n",
    "model = SimpleDFA(input_size, hidden_size, output_size, hidden_layers_number)\n",
    "model.Init_weights()  # Initialize the weights\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train the network using DFA and print XOR accuracy\n",
    "train(model, data, targets, loss_fn, learning_rate=0.1, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
